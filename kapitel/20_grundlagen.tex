
%% GRUNDLAGEN %% 

\chapter{Grundlagen}

Zur erfolgreichen Durchführung dieses Projekts werden Kernkompetenzen der Softwareentwicklung vorausgesetzt. Diese beschäftigen sich weitestgehend mit Softwaredesign und Architekturstilen. Um zu verstehen, wie eine Architektur die Programmierer bei der Entwicklung einer Software unterstützt, muss zunächst festgelegt werden, welche Eigenschaften der Quellcode erfüllen soll, damit dieser positive Qualitätsmerkmale widerspiegelt. Hierzu wurden gängige Designprinzipien über die Jahre festgelegt. Unter anderem die sogenannten 'SOLID'-Prinzipien, welche im nächsten Abschnitt erläutert werden. Diese tragen bei Architekturansätze miteinander zu vergleichen und bewerten.

\section{SOLID-Prinzipien}

Das weitverbreitete Akronym 'SOLID' steht hierbei für eine Ansammlung von fünf Designprinzipien, namentlich das \acrfull{SRP}, \acrfull{OCP}, \acrfull{LSP}, \acrfull{ISP} und das \acrfull{DIP}. Sie sollen sicherstellen, dass Software auch bei Expansion weiterhin testbar, anpassbar und fehlerfrei bleibt. Die grundlegenden Definitionen hinter den Begriffen lauten wie folgt:

\begin{itemize}[]
	\item \textbf{\acrlong{SRP}: } {Jede Softwarekomponente darf laut SRP maximal eine zugehörige Aufgabe erfüllen. Eine Änderung in den Anforderungen erfordert somit die Anpassung in genau einer einzelnen Komponente. Dies erhöht stark die \Gls{Kohasion} der Komponente und senkt die Wahrscheinlichkeit von unerwünschten Nebeneffekten bei Codeanpassungen.}
	\item \textbf{\acrlong{OCP}: } {Zur Sicherstellung, dass eine Änderung in einer Komponente keine Auswirkung auf eine andere besitzt, werden Komponente als 'geschlossen' gegenüber Veränderungen aber 'offen' für Erweiterungen anhand des OCPs definiert. Der erste Teil des Prinzips kann durch ein Interface realisiert werden, welches als geschlossen gilt, da die abstrakten Methoden keine Anpassungen ihrer Signatur erfahren dürfen, sonst müsste der darauf basierender Code angepasst werden. Dennoch können weiterhin Modifikationen durch das Vererben von Klassen oder die Einbindung von neuen Interfaces stattfinden. Dies wird als 'offen' im Sinne des OCPs angesehen.}
	\item \textbf{\acrlong{LSP}: } {Eine wünschenswerte Eigenschaft der Vererbung ist, dass eine Unterklasse S einer Oberklasse T die Korrektheit einer Anwendung nicht beeinflusst, wenn ein Objekt vom Typ T durch ein Objekt vom Typ S ersetzt wird. Dadurch wird die Fehleranfälligkeit bei einer Substitution im Code erheblich gesenkt und der Client kann sichergehen, dass die Funktionalität auch weiterhin den erwarteten Effekt birgt. Da das LSP sich mit der Komposition von Klassen beschäftigt, ist es für die nachfolgende Analyse vernachlässigbar.}
	\item \textbf{\acrlong{ISP}: } {Der Schnitt von Interfaces sollte so spezifisch und klein wie möglich gehalten werden, damit Clients nur Abhängigkeiten zu Funktionalitäten besitzen, welche sie wirklich benötigen. Dadurch wird die Wiederverwendbarkeit und Austauschbarkeit der Komponente gewährleistet.}
	\item \textbf{\acrlong{DIP}: } {Module sollten so unabhängig wie möglich agieren können. Dadurch wird eine erhöhte Testbarkeit und Wiederverwendbarkeit ermöglicht. Das zweiteilige DIP ist von zentraler Bedeutung für eine stabile und flexible Software. Der erste Abschnitt besagt, dass konzeptionell höherliegende Komponente nicht direkt von darunterliegenden Komponenten abhängig sein sollen, sondern die Kommunikation zwischen ihnen über eine Schnittstelle geschieht. Dies ermöglicht die Abstraktion von Funktionsweisen und löst die direkte Abhängigkeit zwischen Modulen auf. Weiterhin wird festgelegt, dass Interfaces nicht an die Implementierung gekoppelt werden sollten, sondern die Implementierung von der Abstraktion abhängen. Dadurch werden die Abhängigkeiten invertiert und ermöglicht beispielhaft die Anwendung von \Gls{DI}.}
\end{itemize}

Architekturen und Kompositionen können anhand dieser Prinzipien bewertet werden. Diese Vorgehensweise wird ebenfalls verwendet, um die nachfolgenden Architekturstile miteinander zu vergleichen. 

\section{Architekturmuster}

Eine Softwarearchitektur beschreibt die grundlegende Struktur der Module, ihre Relationen zueinander und den Kommunikationsstil unter ihnen. Die Wahl der verwendeten Architektur beeinflusst somit die komplette Applikation und ihre Qualitätsmerkmale. Das zu bevorzugende Design einer Anwendung ist stark abhängig von den Anwendungsfällen und ihren Anforderungen. 

In diesem Projekt soll ein Backend-Service erstellt werden, welcher mit den vorgelagerten Systemen über \acrshort{HTTP} und \acrshort{REST} kommuniziert. Dadurch wird die Auswahl der optimalen Architektur beschränkt, da beispielsweise Ansätze wie Model-View-Controller oder Peer-To-Peer für dieses Projektumfeld generell kaum Anwendung finden. Ein Pipe-Filter Architektur eignet sich für die Verarbeitung von einer Vielzahl an Daten, jedoch ist das Abbilden von Entscheidungsstränge und Businessrichtlinien nur umständlich verwirklichbar. Etablierte Architekturen für Backend-Software, welche die Businessprozesse als Kern der Applikation halten, müssen hingegen genauer untersucht werden. Die Schichtenarchitektur und Hexagonale Architektur erfüllen hierbei alle notwendige Bedingungen und bieten ein solides Fundament für das Projekt. Trotz ihrer ähnlichen Ziele, unterscheidet sich der Aufbau auf ersten Blick stark voneinander. In den folgenden Abschnitt werden beide Stile untersucht und anhand ihrer Tauglichkeit für eine Checkout-Software bewertet. Diese Analyse beinhaltet ebenfalls die nativ erhaltene Unterstützung der Entwickler durch die Architekturen zur Umsetzung von Designprinzipien, sodass die generelle Softwarequalität gewährleistet werden kann. 

\subsection{Schichtenarchitektur}

Durch die Einteilung der Softwarekomponenten in einzelne Schichten wird eine fundamentale Trennung der Verantwortlichkeiten und ihre Domänen erzwungen. Die Anzahl der Schichten kann je nach Anwendungsfall variieren, liegt jedoch meist zwischen drei und vier Ebenen. Die meistverbreitete Variante beinhaltet die Präsentations-, Business- und Datenzugriffsschicht. Der Kontrollfluss der Anwendung fließt hierbei stets von einer höheren Schicht in eine tiefere gelegene oder innerhalb einer Ebene zwischen einzelnen Komponenten. Ohne eine konkrete Umkehrung der Abhängigkeiten ist der Abhängigkeitsgraph gleichgerichtet zum Kontrollflussgraph. Hierbei dient Abbildung \ref{fig:Schichtenarchitektur} als eine beispielhafte Darstellung einer solchen Architektur. 

\begin{figure}[htbp]
	\centering
	\large
	\includesvg[width=0.5\textwidth]{svg/Schichtenarchitektur.svg}
	\caption{Beispielhafte Darstellung einer Drei-Schichtenarchitektur}
	\label{fig:Schichtenarchitektur}
\end{figure}

Das Ziel einer Schichtenarchitektur ist die Entkopplung der einzelnen Schichten voneinander und das Erreichen von geringen Abhängigkeiten zwischen den Komponenten. Dadurch sollen Qualitätseigenschaften wie Testbarkeit, Erweiterbarkeit und Flexibilität erhöht werden. Dank dem simplen Aufbau gewann dieser Architekturstil an großer Beliebtheit, jedoch aufgrund der fehlenden Restriktionen erhalten Entwicklern nur geringe Beihilfe zur korrekten Umsetzung des Softwaredesigns. 

Beispielsweise sind die SOLID-Prinzipien nicht oder nur minimal im Grundaufbau verankert. Das \acrlong{SRP} wird durch die Schichteneinteilung unterstützt, da Komponente zum Beispiel nicht den Zugriff auf die Datenbank und gleichzeitig Businesslogik beinhalten kann. Nichtsdestotrotz ist eine vertikale Trennung innerhalb einer Schicht nicht gegeben, daher können weiterhin Komponenten mehrere, konzeptionell verschiedene Aufgaben entgegen des SRPs erfüllen. Um die einzelnen Schichten zu entkoppelt, kann die Kommunikation zwischen den Ebenen durch Schnittstellen geschehen. Das \acrlong{OCP} soll hierbei helfen, dass Änderungen an den Schnittstellen und ihren Implementierungen die Funktionsweise, worauf tieferliegende Schichten basieren, nicht brechen. Die konzeptionelle Zuteilung dieser Interfaces ist entscheidend, um eine korrekte Anwendung des \acrlong{DIP}s zu gewährleisten. Meist wird bei sogenannten CRUD-Applikationen eine Schichtenarchitektur verwendet. \acrshort{CRUD} steht im Softwarekontext für '\textbf{Cr}eate \textbf{U}pdate \textbf{D}elete', somit sind Anwendungen gemeint, welche Daten mit geringer bis keiner Geschäftslogik erzeugen, bearbeiten und löschen. Im Kern einer solchen Software liegen die Daten selbst, dabei werden Module und die umliegende Architektur angepasst, um die Datenverarbeitung zu vereinfachen. Dadurch richten sich oft die Abhängigkeiten in einer Schichtenarchitektur von der Businessschicht zur Datenzugriffsschicht. Bei einer Anwendung, welche der Hauptbestandteil aus Businesslogik besteht, sollte hingegen die Abhängigkeiten stets zur Businessschicht fließen. Daher muss während des Entwicklungsprozesses stets die konkrete Einhaltung des DIPs beachtet werden, da entgegen der intuitiven Denkweise einer Schichtenarchitektur gearbeitet wird. Folglich bietet dieser Architekturansatz zwar einerseits einen hohen Grad an Simplizität, jedoch andererseits sind die SOLID-Prinzipien nur gering in dem Grundaufbau wiederzuerkennen.


\subsection{Hexagonale Architektur}

%Dependency Injection?

Durch weitere architektonische Einschränkungen können Entwickler zu besseren Softwaredesign gezwungen werden, ohne dabei die Implementierungsmöglichkeiten einzuengen. Dieser Denkansatz wird in der von Alistair Cockburn geprägten Hexagonalen Architektur angewandt, indem eine klare Struktur der Softwarekomposition vorgegeben wird. Hierbei existieren drei Bereiche in denen die Komponenten angesiedelt sein können, namentlich die primären Adapter, der Applikationskern und die sekundären Adapter. 

Die gesamte Kommunikation zwischen den Adaptern und dem Applikationskern findet über sogenannte Ports statt. Diese dienen als Abstraktionsschicht und sorgen für Stabilität und schützen den Kern vor Codeänderungen. Realisiert werden Ports meist durch Interfaces, welche hierarchisch dem Zentrum zugeteilt und deren Design durch diesen maßgeblich bestimmt werden. Somit erfolgt eine erzwungene Einhaltung des \emph{\acrlong{DIP}}, wodurch die Applikationslogik von externen Systemen und deren konkreten Implementierungen entkoppelt wird. Dies erhöht drastisch Qualitätsmerkmale der Anwendung, wie beispielsweise geringe Kopplung zwischen Komponenten, Wiederverwendbarkeit und Testbarkeit.

Unter den Adaptern fallen jegliche Komponenten, welche als Schnittstellen zwischen externen Systemen und der Geschäftslogik dienen. Dabei werden die primären Adapter von außerhalb angestoßen und tragen hierbei den Steuerfluss durch einen wohldefinierten Port in den Applikationskern. Zu diesen externen Systemen zählen Benutzerinterfaces, Kommandokonsolen sowie Test-Cases. Andererseits bilden alle Komponenten, welche den Steuerfluss von dem Applikationskern zu externen Systemen tragen, die Gruppe der sekundären Adapter. Hierbei entsteht der Impuls im Vergleich zu den primären Adaptern nicht außerhalb der Applikation sondern innerhalb. Die, von den sekundären Adaptern angesprochenen Systemen, können beispielsweise Datenbanken, Massage-Broker und jegliche Nachbarsysteme sein. 

Letztendlich werden alle übrigen Module im Applikationskern erschlossen. Diese beinhalten Businesslogik und sind komplett von äußeren Einflussfaktoren entkoppelt. Der beschriebene Aufbau wird in Grafik \ref{fig:HexagonaleArchitektur} veranschaulicht.

\begin{figure}[htbp]
	\centering
	\includesvg[width=0.60\textwidth]{svg/HexagonaleArchitektur.svg}
	\caption{Grundstruktur einer Hexagonalen Architektur}
	\label{fig:HexagonaleArchitektur}
\end{figure}

Das Speichern von Daten in einer hexagonalen Applikation ist ein simpler Anwendungsfall, welcher im Folgenden beispielhaft dargestellt wird. 

Ein Webclients überträgt an eine Schnittstelle des Systems Daten, wodurch er den Steuerfluss in einem sogenannten Controller initiiert. Dieser ist den primären Adaptern zugeteilt und erledigt Aufgaben, wie Authentifizierung, Datenumwandlung und erste Fehlerbehandlungen. Über einen entsprechenden Port wird der Kern mit den übergebenen Daten angesprochen. Innerhalb des Applikationszentrums werden alle business-relevanten Aufgaben erfüllt. Darunter fallen das logische Überprüfen der Daten anhand von Businessrichtlinien, Erstellen neuer Daten und die Steuerung des Entscheidungsflusses. In diesem Anwendungsfall sollen die Daten in einer Datenbank abgespeichert werden. Dementsprechend wird aus dem Anwendungskern über einen weiteren Port ein sekundäre Adapter aufgerufen, welcher für das persistieren von Daten in der Datenbank zuständig ist. \comment{Abruptes Ende. Hinleitung zur Bewertung?}

Anhand des Aufbaus einer Hexagonalen Architektur kann hinsichtlich der SOLID-Prinzipien im Vergleich zur Schichtenarchitektur folgendes Fazit formuliert werden:

\begin{itemize}[noitemsep,nolistsep,topsep=-2pt]
	\item \textbf{\acrshort{SRP}: } {Durch den Aufbau wird eine strengere konzeptionelle Trennung der Verantwortlichkeiten erzwungen. Dies wirkt sich positiv auf die Einhaltung des \acrlong{SRP}s aus.}
	\item \textbf{\acrshort{OCP} \& \acrshort{ISP}: } {Als Folge der Einführung von Ports zwischen den Applikationskern und den business-irrelevanten Komponenten ist die Anwendung der beiden Prinzipien erleichtert und teilweise vorausgesetzt. Die Applikation profitiert von erhöhter Stabilität und Kohäsion. }
	\item \textbf{\acrshort{DIP}: } {Mithilfe des \acrlong{DIP}s ist das Austauschen von Komponenten möglich, ohne dabei den Businesskern verändern zu müssen. Dies entkoppelt nicht nur den wichtigsten Bestandteil der Applikation, sondern fördert auch die Testbarkeit enorm. Durch eine native Invertierung der Abhängigkeiten bei korrekter Umsetzung der Hexagonalen Architektur gewinnt die Software vielen positiven Qualitätsmerkmalen.}
\end{itemize}


Abschließend lässt sich die Schlussfolgerung bilden, dass für eine Checkout-Software mit intensiver Businesslogik der Einsatz einer Hexagonalen Architektur zu empfehlen ist. Nicht nur ergibt sich eine natürlichere Einhaltung der SOLID-Prinzipien, sondern der Applikationskern wird ebenfalls in den Vordergrund gerückt. Anzumerken ist, dass erfahrene Entwickler jedoch ebenfalls mit einer Schichtenarchitektur ein gleiches Maß an Softwarequalität erzielen können, sofern die Designprinzipien diszipliniert eingehalten werden. 

% TODO: https://confluence.media-saturn.com/display/crosschannelcheckout/Domain+Driven+Design
\section{Domain-Driven Design}

Bei der Entwicklung von Software, welche mehr als triviale Anwendungsfälle einer CRUD-Anwendung erfüllen soll, besteht stets die Gefahr bei steigender Anzahl von Anforderungen und Änderungen zu einem sogenannten 'Big Ball of Mud' zu verschmelzen. Die bestehende Architektur wird undurchschaubar, Entstehungschancen für Bugs steigen und die Businessanforderungen finden sich überall verteilt in der Anwendung wieder. Somit kann die Wartbarkeit der Software nicht mehr gewährleistet werden und ihre Langlebigkeit ist stark eingeschränkt. Die oben analysierten Architekturstile können bei strikter Umsetzung dieses Risiko einschränken, jedoch bestimmen sie nur begrenzt wie das zugrundeliegende Datenmodell und die damit verbundenen Komponente designt werden sollen. In dem Buch \citetitle{Evans.2011} hat Eric Evans im Jahre 2003 zu diesem Zweck Domain-Driven Design entwickelt. Grundlegend wird durch diese Herangehensweise die Businessprozesse in den Vordergrund gerückt, der Problemraum in Domains eingeteilt und Richtlinien für das Design des Domainmodells festgelegt. \acrlong{DDD}, kurz \acrshort{DDD}, ist nicht gebunden an die darunterliegende Architektur oder verwendeten Technologien und an verschiedenste Einsatzgebiete anpassbar.

Bevor die Bestandteile von DDD bestimmt werden können, sollte zu Beginn eine ausführliche Umfeldanalyse der Problemebene durchgeführt werden, um festzulegen welche Verantwortungen in den zu bestimmenden Bereich fallen. Somit wird unser Problemraum als eine \emph{Domain} aufgespannt. Der Domainschnitt ist hierbei entscheidend, da basierend auf der Domain die dazugehörigen \emph{Subdomains} und ihre \emph{Bounded Contexts} bestimmt werden. Eine Subdomain bündelt die Verantwortlichkeiten und zugehörigen Anwendungsfälle in eine spezifischeren Bereich der Domain. Zur Bestimmung der Subdomains wird der Problemraum stets aus Businesssicht betrachtet und technische Aspekte werden vernachlässigt. Sollte die Domain zu groß geschnitten sein, sind dementsprechend die Subdomains ebenfalls zu umfangreich. Dadurch ist die Kohäsion der Software gefährdet und führt über den Lauf der Entwicklungsphase zu architektonischen Konflikten. Sollte eine Subdomain multiple Verantwortlichkeiten tragen, kann diese Subdomain weiter in kleinere Subdomains eingeteilt werden. Für einen Domain-Driven Ansatz ist es entscheidend die Definitionsphase gewissenhaft durchzuführen, damit eine stabile Grundlage für die Entwicklung geboten werden kann. 

Als Ausgangspunkt für die Bestimmung der Lösungsebene, werden die Subdomains in sogenannte Bounded-Contexts eingeteilt. Ein Bounded-Context kann eine oder mehrere Subdomains umfassen und bündelt ihre zugehörigen Aufgabengebiete. Wie es in der Praxis häufig der Fall ist, können Subdomains und Bounded-Context durchaus identisch sein. In jedem Bereich sollte nur ein Team agieren, um Konflikte zu vermeiden. Andernfalls kann dies ein Indiz sein, dass die Subdomains zu groß geschnitten worden sind. Jeder Bounded-Context besitzt zudem eine zugehörige Ubiquitous Language. Die Festlegung der \emph{Ubiquitous Language} stellt einen wichtigen Schritt in deinem Domain-Driven Ansatz dar. Diese definiert die Bedeutung von Begriffen, welche durch die Stakeholder und das Business verwendet werden, eindeutig. Dadurch können Missverständnisse in der Kommunikation zwischen dem Business und den Entwicklern vorgebeugt und eventuelle Inkonsistenzen aufgedeckt werden. Der größte Vorteile ergibt sich allerdings, sobald auch das Datenmodell diese Sprache widerspiegelt. Entities können Nomen darstellen, Funktionen können Verben realisieren und Aktionen können als Event verwirklicht werden. Somit sind Businessprozesse auch im Quelltext wiederzufinden. Folglich steigert dies die Verständlichkeit und Wartbarkeit der Software. Zudem lassen sich Testfälle und Anwendungsfälle leichter definieren und umsetzten. Wichtig ist, dass diese Sprache nur innerhalb eines Bounded-Context gültig ist. Beispielhaft kann der Begriff 'Kunde' in einem Onlineshop einen zivilen Endkunden, jedoch im Wareneingang eine Lieferfirma beschreiben. Daher ist bei der Kommunikation zwischen Teams unterschiedlicher Subdomains zu beachten, dass Begriffe eventuell unterschiedliche Bedeutung besitzen. 

Die  Domains, Subdomains, Bounded-Contexts und ihre Kommunikation zueinander wird durch eine Context-Map dargestellt. Diese stellt ein wichtiges Artefakt der Definitionsphase dar und kann als Tool zur Bestimmung von Verantwortlichkeiten und Einteilung neuer Anforderungen in die Domains benutzt werden. Sollte eine eindeutige Zuteilung nicht möglich sein, spricht dies für eine Entstehung eines neuen Bounded-Contexts und eventuell einer neuen Subdomain. Sowie eine Software Anpassungen erlebt, entwickelt sich die Context-Map ebenfalls stetig weiter. Zur Veranschaulichung wurde in Abbildung \ref{fig:Context-Map-Example} das Personalwesens eines Unternehmens als Domain ausgewählt und in Subdomains bzw. Bounded-Contexts aufgeteilt. Abhängig von der Unternehmensgröße und -strategie kann der Schnitt der Bounded-Contexts auch umfassender oder spezialisierter ausfallen.

%TODO: Figure als Anhang?
%TODO: Communcation between Subdomains or BoundedContexts

\begin{figure}
	\centering
	\includesvg[width=0.85\textwidth, inkscapelatex=false, height=0.85\textwidth]{svg/ExampleDomain.svg}
	\caption{Beispiel einer Context-Map anhand des Personalwesens}
	\label{fig:Context-Map-Example}
\end{figure}

Innerhalb eines Bounded-Contexts wird die grundlegende Architektur durch das zugehörige Team bestimmt. Je nach Sachverhalt des jeweiligen Kontexts kann sich diese stark von zwischen Bounded-Contexts unterscheiden. Beliebte Modellierungs- und Designstile in Verbindung mit DDD sind unter anderem Microservices, CQRS, Event-Driven Design, Schichtenarchitektur und Hexagonale Architektur. In den vorhergehenden Unterkapiteln wurden bereits die Vorzüge und Nachteile der zwei zuletzt genannten Architekturen erläutert. Auf Basis dieser Analyse wird generell für komplexere Software eine Hexagonale Architektur bevorzugt. Zudem verfolgen Domain-Driven Design und Hexagonale Architektur ähnliche Ziele, wodurch die Software natürlich an Kohäsion und Stabilität gewinnt. Im Zentrum der beiden steht das Domain-Modell, welches ohne Abhängigkeiten zu externen Modulen arbeitet. Primäre und Sekundäre Adapter sind hierzu technisch notwendige Komponente, welche durch fest definierte Ports auf den Applikationskern zugreifen können. Somit ermöglicht die Kombination aus Domain-Driven Design und Hexagonaler Architektur in Zeiten von häufigen technischen Neuheiten und komplexen Businessanforderungen weiterhin eine anpassbare, testbare und übersichtliche Software zu verwirklichen.

Auf ein solches solides Grundgerüst wird mithilfe der Kenntnisse über den Bounded-Context das Domain-Modell gesetzt. Es umfasst sowohl die Datenhaltung als auch das zugehörige Verhalten, wie zum Beispiel die Erstellung von Objekten, die Modifikation ihrer Attribute oder die dauerhafte Speicherung. Für diesen Zweck existieren in Domain-Driven Design mehrere Arten von Komponente, welche anhand ihrer Verantwortlichkeiten zugeordnet werden. Die korrekte Zuordnung der Klassen und ihrer Rollen in DDD ist entscheidend für ein skalierbares Modell, daher wird in den folgenden Unterkapiteln ein zentraler Überblick über die einzelnen Bestandteile ausgeführt.

\subsection{Value Object}

Die Value Objects bilden eine Möglichkeit zusammengehörige Daten zu gruppieren. Entscheidend ist hierbei die Frage, durch welche Eigenschaft der Zusammenschluss identifiziert wird. Die Identität eines Value Object wird alleinig durch die Gesamtheit ihrer Attribute bestimmt. Somit sind zwei Value Objects mit gleichen Werten auch identisch und miteinander ersetzt bar. 

Ein konkretes Beispiel wäre eine Klasse \emph{Preis}, welche die Attribute für Bruttobetrag, Nettobetrag und Mehrwertsteuer enthält. In den meisten Bounded-Contexts sind alleinig die konkreten Beträge von Interesse. Sollte ein Preis die gleichen Wertebelegung besitzen, gelten sie somit als identisch und austauschbar. Bei einer Aktualisierung eines Preises, kann das Objekt gelöscht und durch ein neuen Preis mit den gegenwärtigen Werten ersetzt werden. 

Aus diesen Grund gelten Value Objects als \gls{immutable}, da sie selbst keinen Werteverlauf besitzen. Dies gilt als positives Designmuster, da unveränderbare Objekte eine erhöhte Wiederverwendbarkeit genießen und unerwünschte Seiteneffekte unterdrücken. Weiterhin ist ein Resultat aus dieser Richtlinie, dass sie selbst keinen Lebenszyklus besitzen, jegliche eine Momentaufnahme des Applikationszustandes darstellen.

\subsection{Entity}

Im Gegenzug zu einem Value Object wird eine Entity nicht durch ihre Werte identifiziert, sondern behalten bei Wertanpassung die gleiche Identität bei. Folglich gelten hier zwei Entities mit einer identischer Wertbelegung als ungleich und repräsentieren unterschiedliche Objekte.

Eine Klasse \emph{Kunde} stellt einen guten Vertreter dieser Kategorie dar. In vielen Bounded-Contexts wird ein Kunde durch eine eindeutige Id ausgewiesen. Somit sind zwei Kunden mit gleichen Namen dennoch nicht die gleichen Personen. Sollte eine Person einen Namenswechsel erfahren, muss das zugehörige Objekt ebenfalls aktualisiert werden.

Daher folgt auch der Unterschied zu den Value Objects, dass eine Entity durchaus einen Lebenszyklus aufweisen. Sie werden erstellt, erhalten Anpassungen und irgendwann vom System wieder gelöscht.

In der Entity werden Businessanforderungen, welche sich auf ihre Daten beziehen, direkt implementiert. Dadurch wird eine hohe Kohäsion erzeugt und entsprechend des Information-Expert-Prinzips korrekt verankert.
%TODO: Information Expert in gls

%TODO: Hier Vergleich von Entity vs VO oder erst später?

\subsection{Aggregate}

Innerhalb des Bounded-Context ist ein Aggregate ein Verbund aus Entities und Value Objects, welches von außen als eine einzige Einheit wahrgenommen wird. Externe Komponente dürfen ein Aggregat nur durch das sogenannte Aggregate Root referenzieren und nicht direkt auf enthaltene Objekte zugreifen. Es stellt die Schnittstelle zwischen dem Aggregate und der Außenwelt dar. 

Im Bereich der Personalverwaltung ist ein mögliches Aggregat das des \emph{Mitarbeiter}s. Das Aggregat Root ist die Klasse \emph{Mitarbeiter} selbst. Diese beinhaltet Value Objects, wie \emph{Gehalt} und \emph{Abteilung}. Zu beachten ist, dass abhängig vom jeweiligen Bounded-Context zum Beispiel der Werteverlauf des Gehalt dieses Mitarbeiters vielleicht relevant ist und dementsprechend als eine Entity realisiert werden kann.

Um ein effektives Design der Aggregates zu gewährleisten, wurden einige Einschränkungen an Aggregates beschlossen. Unter anderem müssen Businessanforderungen bzw. Invarianten der enthaltenen Objekte vor und nach einer Transaktion erfüllt sein. Dadurch sind die Aggregates-Grenzen durch den minimalen Umfang der transaktionalen Konsistenz ihrer Komponente gesetzt. Zur Folge dessen, wird für jedes Select oder Update eines Datensatzes immer das komplette Aggregat aus der Datenbank geladen. Große Aggregates leiden aus diesem Grund an eingeschränkter Skalierbarkeit und Performance. Eine weitere Bedingung ist, das pro Transaktion jeweils nur ein Aggregat bearbeitet werden darf. Dies schränkt umfangreichere Aggregate durch fehlende Parallelität weiter ein. Bei Anwendung der letzteren Regel an die Mitarbeiter-Klasse, wäre es nicht möglich das Gehalt und die Abteilung durch zwei unterschiedliche Personalmitarbeiter anzupassen, da eine Transaktion der beiden Änderungen auf einen veralteten Stand operiert und zur Vermeidung eines Lost Updates zurückgerollt werden muss. 

%TODO: gls Lost Update und eventuell Select und Update

Im Falle, dass ein Anwendungsfall die Anpassung zweier Aggregates benötigt, kann dies durch eventuelle Konsistenz ermöglicht werden. Dadurch entsteht kurzzeitig ein inkonsistenter Stand der Daten, da zwei Transaktionen asynchron gestartet werden. In vielen Fällen ist ein Verzug der Konsistenz aus Sicht der Businessanforderungen akzeptabel und stellt eine gute Alternative zur Zusammenführung der beiden Aggregates dar.

%TODO: CQRS?


\subsection{Applicationservice}

Aufgaben, welche kein Domainwissen erfordert, werden in den Applicationservices realisiert. Dazu gehören das Management von Transaktionen, simple Ablaufsteuerung und Aufrufe anderer Service oder Funktionen eines Aggregate Roots. Um Nebeneffekte ausschließen zu können und Parallelität zu ermöglichen, müssen die Applicationservice ohne Zustand designt werden. Innerhalb dieser Service dürfen zudem keine Businessanforderungen enthalten sein oder Invarianten überprüft werden, dieser Aufgabenbereich wird durch die Domainservices abgedeckt.

\subsection{Domainservice}

Soweit anwendbar, werden meist alle Businessanforderungen direkt in den  zuständigen Entities oder Value Objects realisiert. Allerdings existieren Fälle, in denen keine klare Zuteilung der Aufgaben möglich ist. Dies kann beispielsweise auftreten wenn sich der Prozess über zwei oder mehr Aggregates spannt. In diesem Fall wird die Funktionalität in einem Domainservice ausgelagert. Ein weiterer Grund für die Anwendung eines Domainservices kann sein, dass die auszuführende Logik Abhängigkeiten zu anderen Services besitzt. Da das Datenmodell selbst keine Referenz auf die Domainservices haben, kann der Methodenaufruf nicht in dem Klasse selbst geschehen. Analog zu den Applicationservices werden Domainservice zustandslos implementiert.

\subsection{Factory}

Die wiederholten Erstellung von komplexen Objekten kann unnötigen Platz im Quelltext einnehmen und die Übersichtlichkeit einschränken. Dieser Effekt wird vervielfacht, sollte das Codefragment an verschiedenen Stellen auftreten. Zur Auslagerung der Objekterzeugung sind sogenannte Factories gedacht. Sie nehmen alle nötigen Daten entgegen und geben das gefragte Objekt zurück.

\subsection{Repository}

Eine Grundfunktion von allen Anwendungen stellt die Speicherung und das Laden von Daten dar. Mithilfe von Repositories wird der Datenbankzugriff ermöglicht und orchestriert. In Domain-Driven Design benötigt ein Aggregate ihr eigenes Repositorie, da sie unabhängig voneinander geladen werden müssen. Durch diese Zuordnung der Zuständigkeiten wird die konzeptionelle Abhängigkeit der Domain von den Datenbanken getrennt. Die Kommunikation mit einem Repository sollte stets über ein fest definiertes Interface geschehen, damit bei Änderungen der darunterliegenden Datenbanktechnologie der Domainkern unbetroffen bleibt. 

%TODO: Above klingt sehr stark nach Wiki: https://de.wikipedia.org/wiki/Domain-driven_Design

Mithilfe des, in diesem Kapitel erarbeiteten, Wissen wurden die Grundgedanken hinter Designprinzipien verdeutlicht und bildet somit ein solides Fundament für die Durchführung dieses Projekts. Im folgendem wird die Planungsphase des Proof-of-Concepts erläutert.


















































