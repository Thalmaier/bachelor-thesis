
%% GRUNDLAGEN %% 

\chapter{Grundlagen}

Zum erfolgreichen Verständnis dieses Bachelorthemas werden Kernkompetenzen der Softwareentwicklung vorausgesetzt. Diese beschäftigen sich weitestgehend mit Softwaredesign und Architekturstilen. Um nachzuvollziehen, wie eine Architektur die Programmierer bei der Entwicklungsphase unterstützt, muss zunächst festgelegt werden, welche Eigenschaften der Quellcode erfüllen soll, damit dieser positive Qualitätsmerkmale widerspiegelt. Hierzu wurden gängige Designprinzipien über die Jahre festgelegt. Unter anderem die sogenannten 'SOLID'-Prinzipien, die dazu beitragen Architekturansätze miteinander zu vergleichen und zu bewerten.

\section{SOLID-Prinzipien}

Das weitverbreitete Akronym 'SOLID' steht für eine Ansammlung von fünf Designprinzipien, namentlich das \acrfull{SRP}, \acrfull{OCP}, \acrfull{LSP}, \acrfull{ISP} und das \acrfull{DIP}. Sie sollen sicherstellen, dass Software auch mit zunehmenden Funktionsumfang weiterhin testbar, anpassbar und fehlerfrei bleibt \cite{Martin.2000, Martin.2018}. Die grundlegenden Definitionen hinter den Begriffen lauten wie folgt:

\begin{itemize}[]
	\item \textbf{\acrlong{SRP}: } {Jede Softwarekomponente darf laut SRP maximal eine zugehörige Aufgabe erfüllen. Eine Änderung in den Anforderungen erfordert somit die Anpassung in genau einer einzelnen Komponente. Dies erhöht stark die \Gls{Kohasion} der Komponente und senkt die Wahrscheinlichkeit von unerwünschten Nebeneffekten bei Codeanpassungen. \cite{Martin.SRP, Martin.2018}}
	\item \textbf{\acrlong{OCP}: } {Zur Sicherstellung, dass eine Änderung in einer Komponente keine Auswirkung auf eine andere besitzt, werden diese als 'geschlossen' gegenüber Veränderungen aber 'offen' für Erweiterungen definiert. Der erste Teil des Prinzips kann durch ein Interface realisiert werden. Es gilt als geschlossen, da die Implementierungen keine Signaturänderungen der im Interface definierten Methoden erfahren dürfen. Ansonsten müsste der darauf basierender Code ebenfalls bearbeitet werden. Dennoch können weiterhin Modifikationen durch das Vererben von Klassen oder die Einbindung von neuen Interfaces stattfinden. Dies wird als 'offen' im Sinne des OCPs angesehen. \cite{Martin.2018, Meyer.2009}}
	\item \textbf{\acrlong{LSP}: } {Eine wünschenswerte Eigenschaft der Vererbung ist, dass eine Unterklasse S einer Oberklasse T die Korrektheit einer Anwendung nicht beeinflusst, wenn ein Objekt vom Typ T durch ein Objekt vom Typ S ersetzt wird. Dadurch wird die Fehleranfälligkeit bei einer Substitution im Code erheblich gesenkt und der Client kann sichergehen, dass die Funktionalität auch weiterhin den erwarteten Effekt hat. Da sich das LSP mit der Komposition von Klassen beschäftigt, ist es für die nachfolgende Architekturanalyse vernachlässigbar. \cite{Martin.2018, Liskov.1994}}
	\item \textbf{\acrlong{ISP}: } {Der Schnitt von Interfaces sollte so spezifisch und klein wie möglich gehalten werden, damit Clients nur Abhängigkeiten zu Funktionalitäten besitzen, welche sie wirklich benötigen. Dadurch wird die Wiederverwendbarkeit und Austauschbarkeit der Komponente gewährleistet. \cite{Martin.2018}\cite[S. 135ff.]{Martin.2003}}
	\item \textbf{\acrlong{DIP}: } {Module sollten so unabhängig wie möglich agieren können. Dadurch wird eine erhöhte Testbarkeit und Wiederverwendbarkeit ermöglicht. Das zweiteilige DIP ist von zentraler Bedeutung für eine stabile und flexible Software. Hierbei sollen konzeptionell höhere Komponente nicht direkt auf darunterliegende Komponente angewiesen sein, sondern die Kommunikation zwischen ihnen über ein Interface geschehen. Dies erlaubt die Abstraktion von Funktionsweisen und löst die direkte Abhängigkeit zwischen Modulen auf. Weiterhin wird festgelegt, dass Interfaces nicht an die Implementierung gekoppelt werden sollten, sondern auf deren Abstraktionen beruhen \cite{Martin.1996, Martin.2018}. Dadurch sind die Abhängigkeiten invertiert, was beispielhaft die Anwendung von \Gls{DI} ermöglicht \cite{Fowler.2004}.}
\end{itemize}

\section{Architekturmuster}

Eine Softwarearchitektur beschreibt die grundlegende Struktur der Module, ihre Relationen zueinander und den Kommunikationsstil unter ihnen. Die Wahl der verwendeten Architektur beeinflusst somit die komplette Applikation und ihre Qualitätsmerkmale. Das zu bevorzugende Design einer Anwendung ist gekoppelt an die Anwendungsfälle und ihre Anforderungen. 

In diesem Projekt soll ein Backend-Service erstellt werden, welcher mit den vorgelagerten Systemen über \acrshort{HTTP} und \acrshort{REST} kommuniziert, wodurch die Auswahl der Architekturen beschränkt wird. Ansätze wie Peer-to-Peer, welche eine Kommunikation zwischen zwei gleichberechtigten Knoten bereitstellen, sind somit in diesem Anwendungsgebiet nur bedingt vertreten. Etablierte Architekturen für Backend-Software, welche die Businessprozesse als Kern der Applikation halten, werden hingegen genauer untersucht. Die Schichtenarchitektur und Hexagonale Architektur bieten ein solides Fundament für das Projekt. Trotz ihrer ähnlichen Ziele, unterscheidet sich der Aufbau augenscheinlich stark voneinander. Im folgenden Abschnitt werden beide Stile untersucht und anhand ihrer Tauglichkeit für eine Checkout-Software bewertet. Diese Analyse beinhaltet ebenfalls die nativ erhaltene Unterstützung der Entwickler durch die Architekturen zur Umsetzung von Designprinzipien, sodass die generelle Softwarequalität gewährleistet werden kann.

\subsection{Schichtenarchitektur}

Durch die Einteilung der Softwarekomponente in einzelne Schichten wird eine Trennung der Verantwortlichkeiten und ihren Aufgaben erzwungen \cite[S. 185]{Buschmann.2011}. Die Anzahl der Schichten kann je nach Anwendungsfall variieren, liegt jedoch meist zwischen drei und vier Ebenen. Eine verbreitete Variante beinhaltet die Präsentations-, Business- und Datenzugriffsschicht. Der Kontrollfluss der Anwendung fließt hierbei stets von einer höheren Schicht in eine tiefere gelegene oder innerhalb einer Ebene zwischen einzelnen Komponenten. Ohne eine konkrete Umkehrung der Abhängigkeiten ist der Abhängigkeitsgraph gleichgerichtet zum Kontrollflussgraph. \cite[S. 17]{Fowler.2011} Hierbei dient Abbildung \ref{fig:Schichtenarchitektur} als eine beispielhafte Darstellung einer solchen Architektur. 

\begin{figure}[htbp]
	\centering
	\large
	\includesvg[width=0.5\textwidth]{svg/Schichtenarchitektur.svg}
	\caption{Beispielhafte Darstellung einer Drei-Schichtenarchitektur}
	\label{fig:Schichtenarchitektur}
\end{figure}

Das Ziel einer Schichtenarchitektur ist die Entkopplung der einzelnen Schichten voneinander und das Erreichen von geringen Abhängigkeiten zwischen den Komponenten. Dadurch sollen Qualitätseigenschaften wie Testbarkeit, Erweiterbarkeit und Flexibilität erhöht werden. Dank dem simplen Aufbau gewann dieser Architekturstil an großer Beliebtheit. Weitere bewertende Apekte einer solchen Softwarestruktur ergeben sich aus der Analyse der SOLID-Prinzipien:

Das \acrlong{SRP} wird durch die Schichteneinteilung unterstützt, da eine Komponente zum Beispiel keine Businesslogik und zugleich Funktionen der Datenzugriffsschicht implementieren kann. Nichtsdestotrotz ist eine vertikale Trennung innerhalb einer Schicht nicht gegeben, daher können weiterhin Klassen mehrere, konzeptionell verschiedene Aufgaben entgegen des SRPs erfüllen. Um die einzelnen Schichten zu entkoppeln, kann die Kommunikation zwischen den Ebenen durch Schnittstellen geschehen. Das \acrlong{OCP} soll hierbei helfen, dass Änderungen an den Schnittstellen und ihren Implementierungen die Funktionsweise, worauf tieferliegende Schichten basieren, nicht brechen. Die logische Zuteilung dieser Interfaces ist entscheidend, um eine korrekte Anwendung des \acrlong{DIP}s zu gewährleisten. Meist wird bei webbasierten CRUD-Applikationen eine Schichtenarchitektur verwendet. \acrshort{CRUD} steht im Softwarekontext für '\textbf{C}eate \textbf{R}ead \textbf{U}pdate \textbf{D}elete', somit sind Anwendungen gemeint, welche Daten mit geringer bis keiner Geschäftslogik erzeugen, bearbeiten und löschen \cite[S. 381]{Martin.1980}. Im Kern einer solchen Software liegen die Daten selbst, dabei werden Module und die umliegende Architektur angepasst, um die Datenverarbeitung zu vereinfachen. Dadurch richten sich oft die Abhängigkeiten in einer Schichtenarchitektur von der Businessschicht zur Datenzugriffsschicht \cite{Layered.SOLID}. Bei einer Anwendung, welche der Hauptbestandteil aus Businesslogik besteht, sollte hingegen die Abhängigkeiten zur Businessschicht fließen. Daher muss während des Entwicklungsprozesses stets die konkrete Einhaltung des DIPs beachtet werden, da entgegen der intuitiven Denkweise einer Schichtenarchitektur gearbeitet wird. Folglich bietet dieser Architekturansatz zwar einerseits einen hohen Grad an Simplizität, jedoch andererseits sind die SOLID-Prinzipien nur gering in dem Grundaufbau wiederzuerkennen.

\subsection{Hexagonale Architektur}

Durch weitere architektonische Einschränkungen können Entwickler zu besseren Softwaredesign gezwungen werden, ohne dabei die Implementierungsmöglichkeiten einzuengen. Dieser Denkansatz wird in der von Alistair Cockburn geprägten Hexagonalen Architektur angewandt, indem eine klare Struktur der Softwarekomposition vorgegeben wird. Hierbei existieren drei Bereiche in denen die Komponenten angesiedelt sein können, namentlich die primären Adapter, der Applikationskern und die sekundären Adapter. \cite{Cockburn.Hexagonal}  

Die gesamte Kommunikation zwischen den Adaptern und dem Applikationskern findet über sogenannte Ports statt. Diese dienen als Abstraktionsschicht, sorgen für Stabilität und schützen den Kern vor Codeänderungen anhand des \acrlong{OCP}s. Realisiert werden Ports meist durch Interfaces, welche hierarchisch dem Zentrum zugeteilt und deren Design durch diesen maßgeblich bestimmt werden. Somit erfolgt die Einhaltung des \emph{\acrlong{DIP}}, wodurch die Applikationslogik von externen Systemen und deren konkreten Implementierungen unabhängig wird. Dies verringert die Kopplung zwischen Komponenten und erhöht zugleich die Testbarkeit der Anwendung. \cite{philipbrown.2014}

Adapter sind Schnittstellen zwischen einem externen System und der Geschäftslogik. So stößt das externe System den primären Adapter an, der daraufhin den Steuerfluss durch einen wohldefinierten Port in den Applikationskern trägt. Zu diesen externen Systemen zählen unter anderem Benutzerinterfaces, Kommandokonsolen sowie Testfälle. Andererseits bilden alle Komponenten, bei denen der Steuerfluss von dem Applikationskern zu den externen Systemen gerichtet ist, die Gruppe der sekundären Adapter. Hierbei entsteht der Impuls im Vergleich zu den primären Adaptern nicht außerhalb der Applikation, sondern innerhalb. Die von den sekundären Adaptern angesprochenen Systeme können beispielsweise Datenbanken, Message-Broker und jegliche Nachbarsysteme sein. Letztendlich werden alle übrigen Module im Applikationskern erschlossen. Diese beinhalten Businesslogik und sind mithilfe der von ihnen zur Verfügung gestellten Ports von konkreten Implementierungen entkoppelt. \cite{hgraca.2017, Griffin.2021b} Der beschriebene Aufbau wird in Abbildung \ref{fig:HexagonaleArchitektur} veranschaulicht. 

\begin{figure}[htbp]
	\centering
	\includesvg[width=0.60\textwidth]{svg/HexagonaleArchitektur.svg}
	\caption{Grundstruktur einer Hexagonalen Architektur}
	\label{fig:HexagonaleArchitektur}
\end{figure}

Das Speichern von Daten in einer hexagonalen Applikation ist ein simpler Anwendungsfall, welcher im Folgenden zur Veranschaulichung beispielhaft beschrieben dargestellt wird. Ein Webclient überträgt an eine Schnittstelle des Systems Daten, wodurch er den Steuerfluss der Applikation initiiert. Die angesprochene Klasse ist den primären Adaptern zugeteilt und erledigt Aufgaben wie Authentifizierung, Datenumwandlung und erste Fehlerbehandlungen. Über einen entsprechenden Port wird der Kern mit den übergebenen Daten angesprochen. Innerhalb des Applikationszentrums werden alle business-relevanten Aufgaben erfüllt. Darunter fallen das logische Überprüfen der Daten anhand von Businessrichtlinien, Erstellen neuer Daten und die Steuerung des Entscheidungsflusses. In diesem Anwendungsfall sollen die Daten in einer Datenbank abgespeichert werden. Dementsprechend wird aus dem Anwendungskern über einen weiteren Port ein sekundärer Adapter aufgerufen, welcher für das Persistieren von Daten in der Datenbank zuständig ist.

Anhand des Aufbaus einer Hexagonalen Architektur kann hinsichtlich der SOLID-Prinzipien im Vergleich zur Schichtenarchitektur folgendes Fazit formuliert werden:

\begin{itemize}[topsep=-2pt]
	\item \textbf{\acrshort{SRP}: } {Durch den Aufbau wird eine strengere konzeptionelle Trennung der Verantwortlichkeiten ermöglicht. Dies wirkt sich positiv auf die Einhaltung des \acrlong{SRP}s aus.}
	\item \textbf{\acrshort{OCP} \& \acrshort{ISP}: } {Als Folge der Einführung von Ports zwischen den Applikationskern und den business-irrelevanten Komponenten ist die Anwendung der beiden Prinzipien erleichtert und teilweise vorausgesetzt. Die Applikation profitiert von erhöhter Stabilität und Kohäsion. }
	\item \textbf{\acrshort{DIP}: } {Mithilfe des Aufbaus einer Hexagonalen Architektur ist das \acrlong{DIP} fest verankert. Dadurch wird das Austauschen von Komponenten ermöglicht, ohne dabei den Businesskern verändern zu müssen. Dies entkoppelt nicht nur den wichtigsten Bestandteil der Applikation, sondern fördert schlussfolgernd auch die Testbarkeit. Durch eine native Invertierung der Abhängigkeiten gewinnt somit die Software viele positive Qualitätsmerkmale. \cite{Alliaume.2018, Martinez.2021}}
\end{itemize}


Abschließend lässt sich die Schlussfolgerung bilden, dass für eine Checkout-Software mit intensiver Businesslogik der Einsatz einer Hexagonalen Architektur zu empfehlen ist. Nicht nur ergibt sich eine natürlichere Einhaltung der SOLID-Prinzipien, sondern der Applikationskern wird ebenfalls in den Vordergrund gerückt. Anzumerken ist, dass erfahrene Entwickler jedoch ebenfalls mit einer Schichtenarchitektur ein gleiches Maß an Softwarequalität erzielen können, sofern die Designprinzipien diszipliniert eingehalten werden, da bei genauer Betrachtung eine Hexagonale Architektur äquivalent mit einer dreiteilige Schichtenarchitektur mit erzwungenem \acrlong{DIP} ist \cite{Seemann.2013} \cite[S. 125ff.]{Vernon.2015}. 

\section{Domain-Driven Design}

In der Entwicklungsphase von komplexer Software besteht stets die Gefahr zu einem sogenannten 'Big Ball of Mud' zu verschmelzen, weil die steigende Anzahl von Anforderungen und Codeänderungen die Übersichtlichkeit des Sourcecodes beeinträchtigt. Die bestehende Architektur wird undurchschaubar, Entstehungschancen für Bugs erhöhen sich und die Businessanforderungen sind überall in der Anwendung verteilt wiederzufinden. Somit kann die Wartbarkeit der Software nicht mehr gewährleistet werden und ihre Langlebigkeit ist stark eingeschränkt. \cite{bbom.1999} Die oben analysierten Architekturstile können bei strikter Umsetzung diese Risiken minimieren, jedoch bestimmen sie nur begrenzt wie das zugrundeliegende Datenmodell und die damit verbundenen Komponenten designt werden sollen. In dem Buch \citetitle{Evans.2011} entwickelte Eric Evans im Jahr 2003 zu diesem Zweck \acrlong{DDD}, kurz \acrshort{DDD}. Der Buchtitel beschreibt bereits den Hauptgedanken hinter Domain-Driven Design. Liegen die Businessanforderungen im Herzen der Software, sollte dementsprechend auch ihre Implementierung zentral verankert sein. Der Applikationskern stellt somit den 'lebenden' Teil der Anwendung dar. Die verbleibenden Komponenten dienen zur Unterstützung der Businesslogik, indem sie benötigte Dienste dem Kern bereitstellen. Die Businessanforderungen werden somit in DDD strukturell aus dem Quelltext hervorgehoben. Das Datenmodell spiegelt zudem die Sprache der Geschäftsprozesse wider, wodurch die Realisierung der Applikationslogik erleichtert wird. Vor allem Anwendungen mit komplexen Entscheidungssträngen und vielen, jederzeit gültigen Konditionen können dadurch übersichtlich implementiert werden. Zu diesem Zweck definiert Domain-Driven Design einige Vorgehensweisen, Richtlinien und Entwurfsmuster, welche in diesem Kapitel erläutert werden. \cite{Evans.2011, Vernon.2015}

\subsection{Unterteilung der Problemebene in Domains und Subdomains}

Der Problemraum eines Projektes spannt in Domain-Driven Design eine \emph{Domain} auf \cite[S. 56]{Vernon.2015}. Dieser Bereich umfasst logisch zusammengehörige Verantwortlichkeiten und Businessprozesse. Anfangs sollte die Domain anhand einer ausführlichen Umfeldanalyse definiert werden, damit alle Aspekte des Problemraums und seine Abhängigkeiten beleuchtet werden. Innerhalb einer Domain liegen die dazugehörigen \emph{Subdomains}. Eine Subdomain repräsentiert einen kleineren, spezifischeren Teil der Domain, wodurch der Problemraum in mehrere Bereiche unterteilt wird. Sie helfen im nachfolgenden Schritt bei der Formulierung der Lösungsebene. Zur Bestimmung der Subdomains werden die Verantwortlichkeiten stets aus Businesssicht betrachtet und technische Aspekte vernachlässigt. Der Domainumfang ist dabei entscheidend. Sollte dieser zu groß geschnitten sein, sind die Subdomains ebenfalls zu weitreichend. Das gefährdet die Kohäsion der Lösungsebene und somit der Software. Über den Verlauf der Entwicklungsphase könnten aufgrund dessen architektonischen Konflikten auftreten. Enthält eine Subdomain mehrere logisch unabhängige Aufgaben, kann sie in kleinere Subdomains weiter unterteilt werden. Für einen Domain-Driven Ansatz ist es entscheidend die Definitionsphase gewissenhaft durchzuführen, damit eine stabile Grundlage für die Umsetzung des Projekts geboten werden kann. \note{}{Quelle hinzufügen!}

\subsection{Bounded-Contexts und ihre Ubiquitous Language}

Als Ausgangspunkt für die Bestimmung der Lösungsebene dienen die sogenannte Bounded-Contexts \cite[S. 57]{Vernon.2015}, welche eine oder mehrere Subdomains umfassen und ihre zugehörigen Verantwortlichkeiten bündeln. Wie es in der Praxis häufig der Fall ist, können Subdomains und Bounded-Context durchaus identisch sein \cite[S. 57]{Vernon.2015}. In jedem Bounded-Context sollte maximal ein Team tätig sein, um Kommunikationsprobleme zu vermeiden und eine klare Zuteilung der Kompetenzen zu gewährleisten \cite{Brandolini.2021}. Jeder Bounded-Context besitzt zudem eine zugehörige \emph{Ubiquitous Language} \cite[S. 62]{Vernon.2015}. Sie wird als wichtiges Bestandteil während der Projektplanung festgelegt und definiert Begriffen, welche durch die Stakeholder und das Business verwendet werden. Dadurch können Missverständnisse in der Kommunikation zwischen dem Business und den Entwicklern vorgebeugt und eventuelle Inkonsistenzen aufgedeckt werden \cite[S. 336f.]{Evans.2011}. Der größte Vorteil ergibt sich allerdings, sobald auch das Datenmodell diese Sprache wiedergibt. Entities können Nomen darstellen, Funktionen können Verben realisieren und Aktionen können als Events verwirklicht werden, wodurch die Businessprozesse auch im Quelltext wiederzufinden sind. Folglich wird die Verständlichkeit und Wartbarkeit der Software \cite[S. 24ff.]{Evans.2011} gesteigert. Zudem werden Entwicklern bei der Umsetzung von Test- und Anwendungsfälle unterstützt, da ihre textuelle Definitionen auf das Datenmodell übertragbar sind. Zu beachten ist, dass die \emph{Ubiquitous Language} nur innerhalb eines Bounded-Context Gültigkeit hat \cite[S. 62]{Vernon.2015}. Beispielhaft kann der Begriff 'Kunde' in einem Onlineshop einen zivilen Endkunden, jedoch im Wareneingang eine Lieferfirma beschreiben. Daher ist bei der Kommunikation zwischen Teams in unterschiedlichen Subdomains zu berücksichtigen, dass Begriffe eventuell verschiedene Bedeutung besitzen.

Die Domains, Subdomains, Bounded-Contexts und ihre Kommunikation zueinander wird durch eine Context-Map dargestellt. Diese ist ein wichtiges Artefakt der Definitionsphase und kann als Werkzeug zur Bestimmung von Verantwortlichkeiten und Einteilung neuer Anforderungen genutzt werden. Sollte eine eindeutige Zuteilung von Funktionalitäten nicht möglich sein, spricht dies für die Entstehung eines neuen Bounded-Contexts und eventuell einer Subdomain. Wie eine Software Anpassungen erlebt, entwickelt sich gleichermaßen die Context-Map stetig weiter. \cite[S. 87ff]{Vernon.2015} Zur Veranschaulichung wurde in Abbildung \ref{fig:Context-Map-Example} das Personalwesens eines Unternehmens als Domain ausgewählt und in Subdomains bzw. Bounded-Contexts aufgeteilt. Abhängig von der Unternehmensgröße und -strategie können die Bounded-Contexts auch umfassender oder feingranularer ausfallen.

\begin{figure}
	\centering
	\footnotesize
	\includesvg[width=0.85\textwidth, height=0.85\textwidth]{svg/ExampleDomainV2.svg}
	\caption{Beispiel einer Context-Map anhand des Personalwesens einer Firma}
	\label{fig:Context-Map-Example}
\end{figure}

\subsection{Kombination von Domain-Driven Design und Hexagonale Architektur}

Innerhalb eines Bounded-Contexts wird die grundlegende Architektur durch das zugehörige Team bestimmt. Diese kann sich je nach Sachverhalt des jeweiligen Anwendungsgebietes stark zwischen den Bounded-Contexts unterscheiden. Beliebte Modellierungs- und Designstile in Verbindung mit DDD sind unter anderem Microservices, \acrshort{CQRS}, Event-Driven Design, Schichtenarchitektur und Hexagonale Architektur \cite[S. 113ff.]{Vernon.2015}. In den vorhergehenden Unterkapiteln wurden bereits die Vorzüge und Nachteile der zwei zuletzt genannten Architekturen erläutert. Auf Basis der Analyse wird generell für komplexere Software eine Hexagonale Architektur bevorzugt. Zudem steht im Zentrum von Domain-Driven Design und Hexagonale Architektur das Domain-Modell, wodurch die Software an Kohäsion und Stabilität gewinnt. Somit ermöglicht deren Kombination in Zeiten von häufigen technischen Neuheiten und komplexen Businessanforderungen weiterhin eine anpassbare, testbare und übersichtliche Software zu implementieren. Auf ein solches solides Grundgerüst wird mithilfe der Kenntnisse über den Bounded-Context das Domain-Modell gesetzt. Es umfasst sowohl die Datenhaltung als auch das zugehörige Verhalten, wie zum Beispiel die Überprüfung von Richtlinien, Modifikation von Attributen oder ihre dauerhafte Speicherung. Für diesen Zweck existieren in Domain-Driven Design mehrere Arten von Komponenten, welche anhand ihrer Verantwortlichkeiten unterschieden werden. Die korrekte Zuordnung der Klassen zu ihren Rollen ist entscheidend für einen skalierbaren Aufbau. Daher wird in den folgenden Unterkapiteln ein zentraler Überblick über die einzelnen Bestandteile aufgeführt.

\subsection{Value Object}

Die Value Objects bilden eine Möglichkeit zusammengehörige Daten zu gruppieren. Entscheidend ist hierbei die Frage, durch welche Eigenschaft der Zusammenschluss identifiziert wird. Die Identität eines Value Object wird alleinig durch die Gesamtheit ihrer Attribute bestimmt. Somit sind zwei Value Objects mit gleichen Werten auch identisch und miteinander austauschbar ohne die Funktionalität der Software zu beeinflussen \cite[S. 227]{Vernon.2015}. Aus diesem Grund gelten Value Objects als \gls{immutable}, da sie selbst keinen Werteverlauf besitzen \cite[S. 99]{Evans.2011}. Eine Neuzuweisung der Attribute ist deshalb nicht möglich. Stattdessen wird die Referenz auf eine andere, angepasste Instanz der Klasse umgesetzt \cite[S. 226]{Vernon.2015}. Dies gilt als ein positives Designmuster, da unveränderbare Objekte eine erhöhte Wiederverwendbarkeit genießen und unerwünschte Seiteneffekte unterdrücken \cite[S. 228f.]{Vernon.2015}. Folglich kann abgeleitet werden, dass sie aufgrund des fehlenden Lebenszyklus lediglich eine Momentaufnahme des Applikationszustandes darstellen.

\textbf{Beispiel:} In den meisten E-Commerce Bounded-Contexts sind alleinig die konkreten Werte eines \emph{Preises}, wie Bruttobetrag, Nettobetrag und Mehrwertsteuer relevant, weshalb dieser meist als Value Object angesehen wird. Sollten Preise die gleichen Wertebelegungen besitzen, gelten sie dementsprechend als identisch. Bei einer Aktualisierung eines Preises, kann das vorherige Objekt gelöscht und durch einen Preis mit den neuen Werten ersetzt werden. Ist es notwendig, den Werteverlauf des Preises über eine Zeitspanne zu verfolgen, wird oftmals eine ID innerhalb der Datenstruktur hinterlegt. Die Identität ist dadurch nur noch von der ID abhängig, nicht mehr von den Werten. Die Definition eines Value Objects trifft auf die Klasse nicht mehr zu und ein Design als Entity ist zu bevorzugen.  

\subsection{Entity}

Im Gegenzug zu einem Value Object wird eine Entity nicht durch den Zugsamenschluss ihrer Werte identifiziert, sondern enthalten ein vordefiniertes Set an \gls{immutable} Attributen, welche ihre Eindeutigkeit bestimmen \cite[S. 94]{Evans.2011}. Auch nach dem Aktualisieren ihrer Informationen bleibt die ursprüngliche Identität bestehen. Demzufolge gelten die Attribute einer Entity als veränderlich und besitzen ihren eigenen Lebenszyklus, auch wenn dieser nicht explizit abgespeichert werden muss \cite[S. 172]{Vernon.2015}. In einer Entity werden Businessanforderungen, die sich auf enthaltenen Daten beziehen, direkt implementiert und ihre \Gls{Invariante}n sichergestellt \cite[S. 208f.]{Vernon.2015}. Dadurch wird eine hohe Kohäsion erzeugt und entsprechend des \Gls{Information-Expert-Prinzip}s korrekt verankert.

\textbf{Beispiel:} Ein \emph{Kunde} innerhalb eines Domainmodells ist ein guter Vertreter einer Entity. In vielen Bounded-Contexts wird ein Kunde durch eine eindeutige ID ausgewiesen. Somit sind zwei Kunden mit identischen Namen dennoch nicht die gleichen Personen. Sollte der Name einer Person angepasst werden, ist ihre Identität weiterhin äquivalent zur vorhergehenden. Invarianten, wie die korrekte Formatierung der hinterlegten E-Mail, können beispielsweise direkt bei der Aktualisierung überprüft werden.


\subsection{Aggregate}

Innerhalb des Bounded-Contexts ist ein Aggregate der Verbund aus Entities und Value Objects, welcher von außen als eine einzige Einheit wahrgenommen wird. Hierbei findet die Gruppierung anhand ihrer logischen Zusammengehörigkeit und Verantwortungen statt. Externe Komponenten dürfen bei Aufruf eines Aggregates nur auf das sogenannte Aggregate Root zugreifen und enthaltene Objekte nicht direkt referenzieren. Das Aggregate Root ist demzufolge eine Schnittstelle zwischen dem Aggregate und der Außenwelt. \cite[S. 126f.]{Evans.2011}

\textbf{Beispiel:} Ein mögliches Aggregate im Bereich des Personalmanagements ist ein \emph{Mitarbeiter}, welches Value Objects, wie \emph{Gehalt} und \emph{Abteilung}, beinhaltet. Die Klasse \emph{Mitarbeiter} ist auch zugleich ihr eigenes Aggregate Root. Bei Gehaltsanpassungen wird eine Funktion der Mitarbeiter-Klasse aufgerufen, welche das neue Gehalt durch Austausch des Value Objects einträgt. In diesem Schritt können Invarianten überprüft werden, sodass beispielsweise ein neues Gehalt nicht negativ oder niedriger als das vorgehende ausfallen darf. Abhängig vom jeweiligen Bounded-Context ist der Werteverlauf des Gehaltes eventuell relevant, weshalb die Klasse stattdessen als eine Entity realisiert werden kann. 

Um die Effektivität von Aggregates zu gewährleisten, wurden in Domain-Driven Design einige Einschränkungen und Richtlinien beschlossen. Businessanforderungen bzw. Invarianten von enthaltenen Objekten müssen stets vor und nach einer Transaktion erfüllt sein. Dadurch sind die Grenzen der Aggregates durch den minimalen Umfang der transaktionalen Konsistenz ihrer Komponenten gesetzt \cite[S. 354]{Vernon.2015}. Als Folge dessen, wird immer das komplette Aggregate aus der Datenbank geladen und zurückgeschrieben. Große Aggregates leiden aus diesem Grund an reduzierter Skalierbarkeit und Performance, da die Datenmenge und notwendigen Operationen auf Seiten der Datenbank an Last gewinnen \cite[S. 355]{Vernon.2015}. Weiterhin sollte pro Transaktion jeweils nur ein Aggregate bearbeitet werden \cite[S. 354]{Vernon.2015}. Dies schränkt umfangreichere Aggregates durch fehlende Parallelität weiter ein. Unter Beachtung der letzten Regel wäre es nicht möglich das Gehalt und die Abteilung der Mitarbeiter-Klasse durch zwei unterschiedliche Personalmitarbeiter zeitgleich anzupassen. Eine der beiden Transaktion würde auf einen veralteten Stand operieren und zur Vermeidung eines \Gls{Lost Update}s zurückgerollt werden. Sollte ein Anwendungsfall die Anpassung zweier Aggregates benötigt, kann eventuelle Konsistenz angewandt werden. Dadurch entsteht kurzzeitig ein inkonsistenter Stand der Daten, da zwei Transaktionen zeitversetzt gestartet werden. In vielen Fällen ist ein Verzug der Konsistenz aus Sicht der Businessanforderungen akzeptabel und ist eine mögliche Alternative für die Zusammenführung der beiden Aggregates. \cite[S. 364]{Vernon.2015}

\subsection{Applicationservice}

Aufgaben, welche kein Domainwissen erfordert, werden in den Applicationservices realisiert. Ihre Aufgabe ist die Bereitstellung von notwendigen Dienstleistungen zur Abwicklung der Businesslogik \cite{Gorodinski.2012}. Dazu gehört das Management von Transaktionen, simple Ablaufsteuerung und Aufrufe anderer Services oder Aggregate Roots. Somit dürfen sie keine Businessanforderungen enthalten oder Invarianten überprüfen, da dies in den Zuständigkeitsbereich der Domainservices fällt \cite[S. 267]{Vernon.2015}. Die Namensgebungen der Klassen und ihrer Funktionen stammen meist aus Begriffen der Ubiquitous Language \cite[S. 105]{Evans.2011}. Um Nebeneffekte ausschließen zu können und Parallelität zu ermöglichen, müssen die Applicationservices zustandslos designt werden \cite[S. 105]{Evans.2011}. 

\subsection{Domainservice}

Soweit anwendbar, werden Businessanforderungen direkt in den zuständigen Entities oder Value Objects sichergestellt. Allerdings existieren Fälle, in denen keine klare Zuteilung der Aufgaben möglich ist. Dies kann beispielsweise auftreten, wenn sich der Prozess über zwei oder mehr Aggregates spannt. In diesem Fall wird die Funktionalität in einem Domainservice ausgelagert. Sollte die auszuführende Logik Abhängigkeiten zu anderen Services besitzt oder die Kohäsion der Entity bzw. des Value Object verringert werden, ist dies ein weiterer Grund für die Nutzung eines Domainservices. Analog zu den Applicationservices werden sie zustandslos implementiert und stammen aus der Ubiquitous Language. Lediglich unterscheiden sie sich darin, dass es Domainservices erlaubt ist Businesslogik umzusetzen und Invarianten zu beinhalten. \cite[S. 268]{Vernon.2015}

\subsection{Factory}

Die wiederholte Erstellung von komplexen Objekten kann unnötigen Platz im Quelltext einnehmen und die Übersichtlichkeit einschränken, vor allem wenn zusätzliche Services zu diesem Zweck benötigt werden. Der Effekt wird verstärkt, wenn das Codefragment an verschiedenen Stellen auftritt. Zur Auslagerung der Objekterzeugung sind sogenannte Factories gedacht. Sie nehmen alle nötigen Daten entgegen und geben das gefragte Objekt zurück. Dadurch wird weitergehend auch die Kohäsion der Applikation gestärkt. \cite[S. 137f.]{Evans.2011}

\subsection{Repository}

Eine Grundfunktion von Applikationen ist das Speichern und Laden von Daten. Repositories ermöglichen und orchestrieren hierbei den Datenbankzugriff \cite[S. 151]{Evans.2011}. In Domain-Driven Design benötigt jedes Aggregate ihr eigenes Repository, da sie unabhängig voneinander geladen werden müssen \cite[S. 401]{Vernon.2015}. Durch diese Zuordnung der Zuständigkeiten wird die konzeptionellen Abhängigkeiten der Domain von den Datenbanken getrennt. Die Kommunikation mit einem Repository sollte über ein fest definiertes Interface geschehen, damit bei Änderungen der darunterliegenden Datenbanktechnologie der Domainkern unbetroffen bleibt \cite[S. 152]{Evans.2011}. \\\\



Die erarbeiteten Grundgedanken hinter Domain-Driven Design, Hexagonaler Architektur und den SOLID-Prinzipien bilden ein stabiles Fundament für die Durchführung des Projekts. Im folgendem wird diese Basis mithilfe der Planungsphase erweitert und die Checkout-Domain durchleuchtet.
