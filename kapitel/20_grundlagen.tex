
%% GRUNDLAGEN %% 

\chapter{Grundlagen}

Zur erfolgreichen Durchführung dieser Bachelorarbeit werden Kernkompetenzen der Softwareentwicklung vorausgesetzt. Diese beschäftigen sich weitestgehend mit Softwaredesign und Architekturstilen. Um zu verstehen, wie eine Architektur die Programmierer bei der Entwicklungsphase unterstützt, muss zunächst festgelegt werden, welche Eigenschaften der Quellcode erfüllen soll, damit dieser positive Qualitätsmerkmale widerspiegelt. Hierzu wurden gängige Designprinzipien über die Jahre festgelegt. Unter anderem die sogenannten 'SOLID'-Prinzipien, welche im nächsten Abschnitt erläutert werden. Sie tragen bei, Architekturansätze miteinander zu vergleichen und bewerten.

\section{SOLID-Prinzipien}

Das weitverbreitete Akronym 'SOLID' steht hierbei für eine Ansammlung von fünf Designprinzipien, namentlich das \acrfull{SRP}, \acrfull{OCP}, \acrfull{LSP}, \acrfull{ISP} und das \acrfull{DIP}. Sie sollen sicherstellen, dass Software auch bei Expansion weiterhin testbar, anpassbar und fehlerfrei bleibt. Die grundlegenden Definitionen hinter den Begriffen lauten wie folgt:

\begin{itemize}[]
	\item \textbf{\acrlong{SRP}: } {Jede Softwarekomponente darf laut SRP maximal eine zugehörige Aufgabe erfüllen. Eine Änderung in den Anforderungen erfordert somit die Anpassung in genau einer einzelnen Komponente. Dies erhöht stark die \Gls{Kohasion} der Komponente und senkt die Wahrscheinlichkeit von unerwünschten Nebeneffekten bei Codeanpassungen.}
	\item \textbf{\acrlong{OCP}: } {Zur Sicherstellung, dass eine Änderung in einer Komponente keine Auswirkung auf eine andere besitzt, werden Komponente als 'geschlossen' gegenüber Veränderungen aber 'offen' für Erweiterungen anhand des OCPs definiert. Der erste Teil des Prinzips kann durch ein Interface realisiert werden, welches als geschlossen gilt, da die abstrakten Methoden keine Anpassungen ihrer Signatur erfahren dürfen, sonst müsste der darauf basierender Code ebenfalls bearbeitet werden. Dennoch können weiterhin Modifikationen durch das Vererben von Klassen oder die Einbindung von neuen Interfaces stattfinden. Dies wird als 'offen' im Sinne des OCPs angesehen.}
	\item \textbf{\acrlong{LSP}: } {Eine wünschenswerte Eigenschaft der Vererbung ist, dass eine Unterklasse S einer Oberklasse T die Korrektheit einer Anwendung nicht beeinflusst, wenn ein Objekt vom Typ T durch ein Objekt vom Typ S ersetzt wird. Dadurch wird die Fehleranfälligkeit bei einer Substitution im Code erheblich gesenkt und der Client kann sichergehen, dass die Funktionalität auch weiterhin den erwarteten Effekt birgt. Da das LSP sich mit der Komposition von Klassen beschäftigt, ist es für die nachfolgende Architekturanalyse vernachlässigbar.}
	\item \textbf{\acrlong{ISP}: } {Der Schnitt von Interfaces sollte so spezifisch und klein wie möglich gehalten werden, damit Clients nur Abhängigkeiten zu Funktionalitäten besitzen, welche sie wirklich benötigen. Dadurch wird die Wiederverwendbarkeit und Austauschbarkeit der Komponente gewährleistet.}
	\item \textbf{\acrlong{DIP}: } {Module sollten so unabhängig wie möglich agieren können. Dadurch wird eine erhöhte Testbarkeit und Wiederverwendbarkeit ermöglicht. Das zweiteilige DIP ist von zentraler Bedeutung für eine stabile und flexible Software. Der erste Abschnitt besagt, dass konzeptionell höhere Komponente nicht direkt auf darunterliegende Komponente angewiesen sein sollen, sondern die Kommunikation zwischen ihnen über eine Schnittstelle geschieht. Dies ermöglicht die Abstraktion von Funktionsweisen und löst die direkte Abhängigkeit zwischen Modulen auf. Weiterhin wird festgelegt, dass Interfaces nicht an die Implementierung gekoppelt werden sollten, sondern die Implementierung auf die Abstraktion beruht. Dadurch werden die Abhängigkeiten invertiert und ermöglicht beispielhaft die Anwendung von \Gls{DI}.}
\end{itemize}

Architekturen und Kompositionen können anhand dieser Prinzipien bewertet werden. Diese Vorgehensweise wird ebenfalls verwendet, um die nachfolgenden Architekturstile miteinander zu vergleichen. 

\section{Architekturmuster}

Eine Softwarearchitektur beschreibt die grundlegende Struktur der Module, ihre Relationen zueinander und den Kommunikationsstil unter ihnen. Die Wahl der verwendeten Architektur beeinflusst somit die komplette Applikation und ihre Qualitätsmerkmale. Das zu bevorzugende Design einer Anwendung ist stark gekoppelt an die Anwendungsfällen und ihren Anforderungen. 

In diesem Projekt soll ein Backend-Service erstellt werden, welcher mit den vorgelagerten Systemen über \acrshort{HTTP} und \acrshort{REST} kommuniziert. Dadurch wird die Auswahl der optimalen Architektur beschränkt, da beispielsweise Ansätze wie Model-View-Controller oder Peer-To-Peer für dieses Projektumfeld generell kaum Anwendung finden. Ein Pipe-Filter Architektur eignet sich für die Verarbeitung von einer Vielzahl an Daten, jedoch ist das Abbilden von Entscheidungsstränge und Businessrichtlinien nur umständlich verwirklichbar. Etablierte Architekturen für Backend-Software, welche die Businessprozesse als Kern der Applikation halten, müssen hingegen genauer untersucht werden. Die Schichtenarchitektur und Hexagonale Architektur erfüllen hierbei alle notwendigen Bedingungen und bieten ein solides Fundament für das Projekt. Trotz ihrer ähnlichen Ziele, unterscheidet sich der Aufbau auf ersten Blick stark voneinander. In den folgenden Abschnitt werden beide Stile untersucht und anhand ihrer Tauglichkeit für eine Checkout-Software bewertet. Diese Analyse beinhaltet ebenfalls die nativ erhaltene Unterstützung der Entwickler durch die Architekturen zur Umsetzung von Designprinzipien, sodass die generelle Softwarequalität gewährleistet werden kann. 

\subsection{Schichtenarchitektur}

Durch die Einteilung der Softwarekomponente in einzelne Schichten wird eine fundamentale Trennung der Verantwortlichkeiten und ihren Aufgaben erzwungen. Die Anzahl der Schichten kann je nach Anwendungsfall variieren, liegt jedoch meist zwischen drei und vier Ebenen. Die meistverbreitete Variante beinhaltet die Präsentations-, Business- und Datenzugriffsschicht. Der Kontrollfluss der Anwendung fließt hierbei stets von einer höheren Schicht in eine tiefere gelegene oder innerhalb einer Ebene zwischen einzelnen Komponenten. Ohne eine konkrete Umkehrung der Abhängigkeiten ist der Abhängigkeitsgraph gleichgerichtet zum Kontrollflussgraph. Hierbei dient Abbildung \ref{fig:Schichtenarchitektur} als eine beispielhafte Darstellung einer solchen Architektur. 

\begin{figure}[htbp]
	\centering
	\large
	\includesvg[width=0.5\textwidth]{svg/Schichtenarchitektur.svg}
	\caption{Beispielhafte Darstellung einer Drei-Schichtenarchitektur}
	\label{fig:Schichtenarchitektur}
\end{figure}

Das Ziel einer Schichtenarchitektur ist die Entkopplung der einzelnen Schichten voneinander und das Erreichen von geringen Abhängigkeiten zwischen den Komponenten. Dadurch sollen Qualitätseigenschaften wie Testbarkeit, Erweiterbarkeit und Flexibilität erhöht werden. Dank dem simplen Aufbau gewann dieser Architekturstil an großer Beliebtheit, jedoch aufgrund der fehlenden Restriktionen erhalten Entwicklern nur geringe Beihilfe zur korrekten Umsetzung des Softwaredesigns. 

Beispielsweise sind die SOLID-Prinzipien nur minimal im Grundaufbau verankert. Das \acrlong{SRP} wird durch die Schichteneinteilung unterstützt, da Komponente zum Beispiel keinen Zugriff auf die Datenbank und Businesslogik gleichzeitig beinhalten können. Nichtsdestotrotz ist eine vertikale Trennung innerhalb einer Schicht nicht gegeben, daher können weiterhin Klassen mehrere, konzeptionell verschiedene Aufgaben entgegen des SRPs erfüllen. Um die einzelnen Schichten zu entkoppelt, kann die Kommunikation zwischen den Ebenen durch Schnittstellen geschehen. Das \acrlong{OCP} soll hierbei helfen, dass Änderungen an den Schnittstellen und ihren Implementierungen die Funktionsweise, worauf tieferliegende Schichten basieren, nicht brechen. Die logische Zuteilung dieser Interfaces ist entscheidend, um eine korrekte Anwendung des \acrlong{DIP}s zu gewährleisten. Meist wird bei sogenannten CRUD-Applikationen eine Schichtenarchitektur verwendet. \acrshort{CRUD} steht im Softwarekontext für '\textbf{Cr}eate \textbf{U}pdate \textbf{D}elete', somit sind Anwendungen gemeint, welche Daten mit geringer bis keiner Geschäftslogik erzeugen, bearbeiten und löschen. Im Kern einer solchen Software liegen die Daten selbst, dabei werden Module und die umliegende Architektur angepasst, um die Datenverarbeitung zu vereinfachen. Dadurch richten sich oft die Abhängigkeiten in einer Schichtenarchitektur von der Businessschicht zur Datenzugriffsschicht. Bei einer Anwendung, welche der Hauptbestandteil aus Businesslogik besteht, sollte hingegen die Abhängigkeiten stets zur Businessschicht fließen. Daher muss während des Entwicklungsprozesses stets die konkrete Einhaltung des DIPs beachtet werden, da entgegen der intuitiven Denkweise einer Schichtenarchitektur gearbeitet wird. Folglich bietet dieser Architekturansatz zwar einerseits einen hohen Grad an Simplizität, jedoch andererseits sind die SOLID-Prinzipien nur gering in dem Grundaufbau wiederzuerkennen.


\subsection{Hexagonale Architektur}

Durch weitere architektonische Einschränkungen können Entwickler zu besseren Softwaredesign gezwungen werden, ohne dabei die Implementierungsmöglichkeiten einzuengen. Dieser Denkansatz wird in der von Alistair Cockburn geprägten Hexagonalen Architektur angewandt, indem eine klare Struktur der Softwarekomposition vorgegeben wird. Hierbei existieren drei Bereiche in denen die Komponenten angesiedelt sein können, namentlich die primären Adapter, der Applikationskern und die sekundären Adapter. 

Die gesamte Kommunikation zwischen den Adaptern und dem Applikationskern findet über sogenannte Ports statt. Diese dienen als Abstraktionsschicht, sorgen für Stabilität und schützen den Kern vor Codeänderungen. Realisiert werden Ports meist durch Interfaces, welche hierarchisch dem Zentrum zugeteilt und deren Design durch diesen maßgeblich bestimmt werden. Somit erfolgt eine erzwungene Einhaltung des \emph{\acrlong{DIP}}, wodurch die Applikationslogik von externen Systemen und deren konkreten Implementierungen unabhängig wird. Dies erhöht drastisch Qualitätsmerkmale der Anwendung, wie beispielsweise geringe Kopplung zwischen Komponenten und Testbarkeit.

Unter den Adaptern fallen jegliche Komponente, welche als Schnittstellen zwischen externen Systemen und der Geschäftslogik dienen. Dabei werden die primären Adapter von außerhalb angestoßen und tragen hierbei den Steuerfluss durch einen wohldefinierten Port in den Applikationskern. Zu diesen externen Systemen zählen unter anderem Benutzerinterfaces, Kommandokonsolen sowie Testfälle. Andererseits bilden alle Komponente, bei denen der Steuerfluss von dem Applikationskern zu den externen Systemen gerichtet ist, die Gruppe der sekundären Adapter. Hierbei entsteht der Impuls im Vergleich zu den primären Adaptern nicht außerhalb der Applikation, sondern innerhalb. Die, von den sekundären Adaptern angesprochenen Systemen, können beispielsweise Datenbanken, Massage-Broker und jegliche Nachbarsysteme sein. 

Letztendlich werden alle übrigen Module im Applikationskern erschlossen. Diese beinhalten Businesslogik und sind komplett von äußeren Einflussfaktoren entkoppelt. Der beschriebene Aufbau wird in Grafik \ref{fig:HexagonaleArchitektur} veranschaulicht.

\begin{figure}[htbp]
	\centering
	\includesvg[width=0.60\textwidth]{svg/HexagonaleArchitektur.svg}
	\caption{Grundstruktur einer Hexagonalen Architektur}
	\label{fig:HexagonaleArchitektur}
\end{figure}

Das Speichern von Daten in einer hexagonalen Applikation ist ein simpler Anwendungsfall, welcher im Folgenden zur Veranschaulichung beispielhaft beschrieben dargestellt wird. Ein Webclient überträgt an eine Schnittstelle des Systems Daten, wodurch er den Steuerfluss in einem sogenannten Controller initiiert. Dieser ist den primären Adaptern zugeteilt und erledigt Aufgaben, wie Authentifizierung, Datenumwandlung und erste Fehlerbehandlungen. Über einen entsprechenden Port wird der Kern mit den übergebenen Daten angesprochen. Innerhalb des Applikationszentrums werden alle business-relevanten Aufgaben erfüllt. Darunter fallen das logische Überprüfen der Daten anhand von Businessrichtlinien, Erstellen neuer Daten und die Steuerung des Entscheidungsflusses. In diesem Anwendungsfall sollen die Daten in einer Datenbank abgespeichert werden. Dementsprechend wird aus dem Anwendungskern über einen weiteren Port ein sekundärer Adapter aufgerufen, welcher für das persistieren von Daten in der Datenbank zuständig ist.

Anhand des Aufbaus einer Hexagonalen Architektur kann hinsichtlich der SOLID-Prinzipien im Vergleich zur Schichtenarchitektur folgendes Fazit formuliert werden:

\begin{itemize}[noitemsep,nolistsep,topsep=-2pt]
	\item \textbf{\acrshort{SRP}: } {Durch den Aufbau wird eine strengere konzeptionelle Trennung der Verantwortlichkeiten erzwungen. Dies wirkt sich positiv auf die Einhaltung des \acrlong{SRP}s aus.}
	\item \textbf{\acrshort{OCP} \& \acrshort{ISP}: } {Als Folge der Einführung von Ports zwischen den Applikationskern und den business-irrelevanten Komponenten ist die Anwendung der beiden Prinzipien erleichtert und teilweise vorausgesetzt. Die Applikation profitiert von erhöhter Stabilität und Kohäsion. }
	\item \textbf{\acrshort{DIP}: } {Mithilfe des \acrlong{DIP}s ist das Austauschen von Komponenten möglich, ohne dabei den Businesskern verändern zu müssen. Dies entkoppelt nicht nur den wichtigsten Bestandteil der Applikation, sondern fördert auch die Testbarkeit enorm. Durch eine native Invertierung der Abhängigkeiten bei korrekter Umsetzung der Hexagonalen Architektur gewinnt die Software vielen positiven Qualitätsmerkmalen.}
\end{itemize}


Abschließend lässt sich die Schlussfolgerung bilden, dass für eine Checkout-Software mit intensiver Businesslogik der Einsatz einer Hexagonalen Architektur zu empfehlen ist. Nicht nur ergibt sich eine natürlichere Einhaltung der SOLID-Prinzipien, sondern der Applikationskern wird ebenfalls in den Vordergrund gerückt. Anzumerken ist, dass erfahrene Entwickler jedoch ebenfalls mit einer Schichtenarchitektur ein gleiches Maß an Softwarequalität erzielen können, sofern die Designprinzipien diszipliniert eingehalten werden, da bei genauer Betrachtung eine Hexagonale Architektur nur eine umgestellte Schichtenarchitektur mit erzwungenem \acrlong{DIP} darstellt. 

\section{Domain-Driven Design}

In der Entwicklungsphase von komplexer Software besteht stets die Gefahr bei steigender Anzahl von Anforderungen und Codeänderungen zu einem sogenannten 'Big Ball of Mud' zu verschmelzen. Die bestehende Architektur wird undurchschaubar, Entstehungschancen für Bugs erhöhen sich und die Businessanforderungen sind überall in der Anwendung verteilt wiederzufinden. Somit kann die Wartbarkeit der Software nicht mehr gewährleistet werden und ihre Langlebigkeit ist stark eingeschränkt. Die oben analysierten Architekturstile können bei strikter Umsetzung diese Risiken einschränken, jedoch bestimmen sie nur begrenzt wie das zugrundeliegende Datenmodell und die damit verbundenen Komponenten designt werden sollen. 

In dem Buch \citetitle{Evans.2011} entwickelte Eric Evans im Jahre 2003 zu diesem Zweck \acrlong{DDD}, kurz \acrshort{DDD}. Der Hauptgedanke hinter Domain-Driven Design ist, dass Applikationen primär zur Bewältigung eines konkreten Problems entwickelt werden und sollten deswegen die Businessanforderungen durch ein strukturiertes Design aus dem Quelltext hervorheben. Das Datenmodell spiegelt folglich die Sprache der Geschäftsprozesse wider, wodurch die Realisierung der Applikationslogik erleichtert wird. Vor allem Anwendungen mit komplexen Entscheidungssträngen und vielen, jederzeit gültigen Konditionen können dadurch übersichtlich implementiert werden. Aus diesem Grund definiert Domain-Driven Design einige Vorgehensweisen, Richtlinien und Entwurfsmuster, welche in diesem Kapitel erläutert werden. 

\subsection{Unterteilung der Problemebene in Domains und Subdomains}

In einem neuen Projekt mit Domain-Driven Design sollte zu Beginn eine ausführliche Umfeldanalyse mitsamt allen relevanten Systemen durchgeführt werden, um festzulegen welche Verantwortungen in den zu bestimmenden Bereich fallen. Der Problemraum des Projekts wird dadurch als eine \emph{Domain} aufgespannt. Hierbei ist der Domainumfang entscheidend, da darauf basierend die dazugehörigen \emph{Subdomains} und ihre \emph{Bounded Contexts} bestimmt werden. Eine Subdomain repräsentiert einen kleineren, spezifischeren Bereich der Domain, welcher logisch zusammenhängende Problemstellungen löst. Zur Bestimmung der Subdomains werden die Verantwortlichkeiten stets aus Businesssicht betrachtet und technische Aspekte vernachlässigt. Sollte die Domain zu groß geschnitten sein, sind dementsprechend die Subdomains ebenfalls zu umfangreich. Dadurch ist die Kohäsion der Software gefährdet und führt über den Verlauf der Entwicklungsphase zu architektonischen Konflikten. Sollte eine Subdomain mehrere logisch unabhängige Aufgaben enthalten, kann diese weiter in kleinere Subdomains unterteilt werden. Für einen Domain-Driven Ansatz ist es entscheidend die Definitionsphase gewissenhaft durchzuführen, damit eine stabile Grundlage für die Projektdurchführung geboten werden kann. 

\subsection{Bounded-Contexts und ihre Ubiquitous Language}

Als Ausgangspunkt für die Bestimmung der Lösungsebene dienen die sogenannte Bounded-Contexts, welche eine oder mehrere Subdomains umfassen und ihre zugehörigen Verantwortlichkeiten bündeln. Wie es in der Praxis häufig der Fall ist, können Subdomains und Bounded-Context durchaus identisch sein. In jedem Bounded-Context sollte maximal ein Team agieren, um Kommunikationsprobleme zu vermeiden und eine klare Zuteilung der Kompetenzen zu gewährleisten. Andernfalls kann dies ein Indiz sein, dass die Subdomains zu groß geschnitten worden sind. Jeder Bounded-Context besitzt zudem eine zugehörige \emph{Ubiquitous Language}. Die Festlegung der \emph{Ubiquitous Language} stellt einen wichtigen Schritt der Projektphase dar. Diese definiert die Bedeutung von Begriffen, welche durch die Stakeholder und das Business verwendet werden, eindeutig. Dadurch können Missverständnisse in der Kommunikation zwischen dem Business und den Entwicklern vorgebeugt und eventuelle Inkonsistenzen aufgedeckt werden. Der größte Vorteil ergibt sich allerdings, sobald auch das Datenmodell diese Sprache wiedergibt. Entities können Nomen darstellen, Funktionen können Verben realisieren und Aktionen können als Event verwirklicht werden. Somit sind Businessprozesse auch im Quelltext wiederzufinden. Folglich steigert dies die Verständlichkeit und Wartbarkeit der Software. Zudem lassen sich Testfälle und Anwendungsfälle leichter definieren und umsetzten. Zu beachten ist, dass diese Sprache nur innerhalb eines Bounded-Context Gültigkeit hat. Beispielhaft kann der Begriff 'Kunde' in einem Onlineshop einen zivilen Endkunden, jedoch im Wareneingang eine Lieferfirma beschreiben. Daher ist bei der Kommunikation zwischen Teams unterschiedlicher Subdomains zu berücksichtigen, dass Begriffe eventuell verschiedene Bedeutung besitzen. 

Die Domains, Subdomains, Bounded-Contexts und ihre Kommunikation zueinander wird durch eine Context-Map dargestellt. Diese ist ein wichtiges Artefakt der Definitionsphase und kann als Werkzeug zur Bestimmung von Verantwortlichkeiten und Einteilung neuer Anforderungen benutzt werden. Sollte eine eindeutige Zuteilung nicht möglich sein, spricht dies für eine Entstehung eines neuen Bounded-Contexts und eventuell einer neuen Subdomain. Gleichermaßen, wie eine Software Anpassungen erlebt, entwickelt sich auch die Context-Map ebenfalls stetig weiter. Zur Veranschaulichung wurde in Abbildung \ref{fig:Context-Map-Example} das Personalwesens eines Unternehmens als Domain ausgewählt und in Subdomains bzw. Bounded-Contexts aufgeteilt. Abhängig von der Unternehmensgröße und -strategie kann der Schnitt der Bounded-Contexts auch umfassender oder detaillierter ausfallen.

\begin{figure}
	\centering
	\footnotesize
	\includesvg[width=0.85\textwidth, height=0.85\textwidth]{svg/ExampleDomainV2.svg}
	\caption{Beispiel einer Context-Map anhand des Personalwesens einer Firma}
	\label{fig:Context-Map-Example}
\end{figure}

\subsection{Kombination von Domain-Driven Design und Hexagonale Architektur}

Innerhalb eines Bounded-Contexts wird die grundlegende Architektur durch das zugehörige Team bestimmt. Je nach Sachverhalt des jeweiligen Kontexts kann sich diese stark zwischen den Bounded-Contexts unterscheiden. Beliebte Modellierungs- und Designstile in Verbindung mit DDD sind unter anderem Microservices, \acrshort{CQRS}, Event-Driven Design, Schichtenarchitektur und Hexagonale Architektur. In den vorhergehenden Unterkapiteln wurden bereits die Vorzüge und Nachteile der zwei zuletzt genannten Architekturen erläutert. Auf Basis dieser Analyse wird generell für komplexere Software eine Hexagonale Architektur bevorzugt. Zudem verfolgen Domain-Driven Design und Hexagonale Architektur ähnliche Ziele, wodurch die Software natürlich an Kohäsion und Stabilität gewinnt. Im Zentrum der beiden steht das Domain-Modell, welches ohne Abhängigkeiten zu externen Modulen arbeitet. Primäre und Sekundäre Adapter sind hierzu technisch notwendige Komponente, die durch fest definierte Ports auf den Applikationskern zugreifen können. Somit ermöglicht die Kombination aus Domain-Driven Design und Hexagonaler Architektur in Zeiten von häufigen technischen Neuheiten und komplexen Businessanforderungen weiterhin eine anpassbare, testbare und übersichtliche Software zu verwirklichen.
\comment{Eventuell weiter ausführen, verdeutlichen. Ist noch etwas vage.}

Auf ein solches solides Grundgerüst wird mithilfe der Kenntnisse über den Bounded-Context das Domain-Modell gesetzt. Es umfasst sowohl die Datenhaltung als auch das zugehörige Verhalten, wie zum Beispiel die Überprüfung von Richtlinien, Modifikation von Attributen oder ihre dauerhafte Speicherung. Für diesen Zweck existieren in Domain-Driven Design mehrere Arten von Komponenten, welche anhand ihrer Verantwortlichkeiten zugeordnet werden. Die korrekte Zuordnung der Klassen und ihrer Rollen in DDD ist entscheidend für einen skalierbaren Aufbau, daher wird in den folgenden Unterkapiteln ein zentraler Überblick über die einzelnen Bestandteile aufgeführt.

\subsection{Value Object}

Die Value Objects bilden eine Möglichkeit zusammengehörige Daten zu gruppieren. Entscheidend ist hierbei die Frage, durch welche Eigenschaft der Zusammenschluss identifiziert wird. Die Identität eines Value Object wird alleinig durch die Gesamtheit ihrer Attribute bestimmt. Somit sind zwei Value Objects mit gleichen Werten auch identisch und miteinander austauschbar ohne die Funktionalität der Software zu beeinflussen. 

Ein konkretes Beispiel wäre eine Klasse \emph{Preis}, welche die Attribute für Bruttobetrag, Nettobetrag und Mehrwertsteuer enthält. In den meisten Bounded-Contexts sind alleinig die konkreten Beträge von Interesse. Sollten Preise die gleichen Wertebelegungen besitzen, gelten sie dementsprechend als identisch. Bei einer Aktualisierung eines Preises, kann das vorgehende Objekt gelöscht und durch einen Preis mit den neuen Werten ersetzt werden. 

Aus diesem Grund gelten Value Objects als \gls{immutable}, da sie selbst keinen Werteverlauf besitzen. Eine Neuzuweisung der Attribute ist somit nicht möglich und stattdessen werden Referenzen auf eine andere, angepasste Instanz der Klasse verlinkt. Dies gilt als ein positives Designmuster, da unveränderbare Objekte eine erhöhte Wiederverwendbarkeit genießen und unerwünschte Seiteneffekte unterdrücken. Weiterhin kann dadurch abgeleitet werden, dass sie selbst keinen eigenen Lebenszyklus besitzen, lediglich eine Momentaufnahme des Applikationszustandes darstellen. Folglich können sie nur in Zusammenhand mit Entities existieren.

\subsection{Entity}

Im Gegenzug zu einem Value Object wird eine Entity nicht durch den Zugsamenschluss ihrer Werte identifiziert, sondern enthalten ein vordefiniertes Set an \gls{immutable} Attributen, welche ihre Eindeutigkeit bestimmen. Auch nach dem Aktualisieren ihrer Informationen bleibt die ursprüngliche Identität bestehen. Demzufolge gelten die Attribute einer Entity als veränderlich und besitzen ihren eigenen Lebenszyklus, auch wenn dieser nicht explizit abgespeichert werden muss.

Ein \emph{Kunde} in einem Domainmodell stellt einen guten Vertreter dieser Kategorie dar. In vielen Bounded-Contexts wird ein Kunde durch eine eindeutige Id ausgewiesen. Somit sind zwei Kunden mit identischen Namen dennoch nicht die gleichen Personen. Sollte der Name einer Person angepasst werden, ist ihre Identität weiterhin äquivalent zur vorherigen.

In einer Entity werden Businessanforderungen, die sich auf enthaltenen Daten beziehen, direkt implementiert und ihre \Gls{Invariante}n sichergestellt. Dadurch wird eine hohe Kohäsion erzeugt und entsprechend des \Gls{Information-Expert-Prinzip}s korrekt verankert.

\subsection{Aggregate}

Innerhalb des Bounded-Context ist ein Aggregate der Verbund aus Entities und Value Objects, welcher von außen als eine einzige Einheit wahrgenommen wird. Hierbei findet die Gruppierung anhand ihrer logischen Zusammengehörigkeit und Verantwortungen statt. Externe Komponente dürfen bei Aufruf eines Aggregates nur auf das sogenannte Aggregate Root zugreifen und nicht direkt enthaltene Objekte referenzieren. Die Root-Klasse stellt demzufolge eine Schnittstelle zwischen dem Aggregate und der Außenwelt dar. 

Ein mögliches Aggregat im Bereich des Personalmanagements ist ein \emph{Mitarbeiter}. Das Aggregat Root ist die Klasse \emph{Mitarbeiter} selbst. Diese beinhaltet Value Objects, wie \emph{Gehalt} und \emph{Abteilung}. Bei Gehaltsanpassungen wird eine Funktion auf der Mitarbeiter-Klasse aufgerufen, welche den neuen Wert durch Austausch des Value Objects einträgt. Hierbei können Invarianten überprüft werden, sodass ein neues Gehalt nicht negativ oder niedriger als das vorgehende ausfallen darf. Zu beachten ist, dass abhängig vom jeweiligen Bounded-Context zum Beispiel der Werteverlauf des Gehaltes dieses Mitarbeiters vielleicht relevant ist und dementsprechend als eine Entity realisiert werden kann. 

Um einen effektiven Aggregationsschnitt zu gewährleisten, wurden einige Einschränkungen und Richtlinien von Aggregates beschlossen. 

Anhand des vorherigen Beispiels kann abgeleitet werden, dass Businessanforderungen bzw. Invarianten der enthaltenen Objekte stets vor und nach einer Transaktion erfüllt sein müssen. Dadurch sind die Grenzen der Aggregates durch den minimalen Umfang der transaktionalen Konsistenz ihrer Komponente gesetzt. Zur Folge dessen, wird immer das komplette Aggregat aus der Datenbank geladen und abgespeichert, sonst könnten die vorgehenden Anforderungen nicht erfüllt werden. Große Aggregates leiden aus diesem Grund an reduzierter Skalierbarkeit und Performance, da die Datenmenge und notwendige Operationen auf Seiten der Datenbank an Last gewinnen. Weiterhin sollte pro Transaktion jeweils nur ein Aggregat bearbeitet werden. Dies schränkt umfangreichere Aggregates durch fehlende Parallelität weiter ein. Bei Beachtung der letzteren Regel wäre es nicht möglich das Gehalt und die Abteilung der Mitarbeiter-Klasse durch zwei unterschiedliche Personalmitarbeiter zeitgleich anzupassen, weil eine der beiden Transaktion auf einen veralteten Stand operieren würde und zur Vermeidung eines \Gls{Lost Update}s zurückgerollt werden muss. 

Im Falle, dass ein Anwendungsfall die Anpassung zweier Aggregates benötigt, kann dies durch eventuelle Konsistenz ermöglicht werden. Dadurch entsteht kurzzeitig ein inkonsistenter Stand der Daten, da zwei Transaktionen zeitversetzt gestartet werden. In vielen Fällen ist ein Verzug der Konsistenz aus Sicht der Businessanforderungen akzeptabel und stellt eine mögliche Alternative zur Zusammenführung der beiden Aggregates dar.

\comment{Ausarbeiten und Ergänzen weil dieser Abschnitt relevant ist für das Thema?}

\subsection{Applicationservice}

Aufgaben, welche kein Domainwissen erfordert, werden in den Applicationservices realisiert. Entgegen der Entities und Value Objects ist ihre Aufgabe die Bereitstellung von notwendigen Dienstleistungen. Dazu gehören das Management von Transaktionen, simple Ablaufsteuerung und Aufrufe anderer Services oder Aggregate Roots. Die Namensgebung der Klasse und ihrer Funktionen stammt meist aus Begriffen der Ubiquitous Language.

Um Nebeneffekte ausschließen zu können und Parallelität zu ermöglichen, müssen die Applicationservice ohne Zustand designt werden. Zusätzlich dürfen sie keine Businessanforderungen enthalten oder Invarianten überprüft. Dies fällt in den Zuständigkeitsbereich der nachfolgenden Gruppierung.

\subsection{Domainservice}

Soweit anwendbar, werden meist alle Businessanforderungen direkt in den  zuständigen Entities oder Value Objects realisiert. Allerdings existieren Fälle, in denen keine klare Zuteilung der Aufgaben möglich ist. Dies kann beispielsweise auftreten, wenn sich der Prozess über zwei oder mehr Aggregates spannt. In diesem Fall wird die Funktionalität in einem Domainservice ausgelagert. Ein weiterer Grund für die Anwendung eines Domainservices kann sein, dass die auszuführende Logik Abhängigkeiten zu anderen Services besitzt oder die Kohäsion der Entity bzw. des Value Object verringert. 

Analog zu den Applicationservices werden Domainservice zustandslos implementiert und finden ihre enthaltene Implementierung aus der Ubiquitous Language. Lediglich ist der Unterschied, dass es Domainservices erlaubt ist Businesslogik umzusetzen und Invarianten zu beinhalten.

\subsection{Factory}

Die wiederholte Erstellung von komplexen Objekten kann unnötigen Platz im Quelltext einnehmen und die Übersichtlichkeit einschränken, vor allem wenn zusätzliche Services benötigt werden. Dieser Effekt wird vervielfacht, sollte das Codefragment an verschiedenen Stellen auftreten. Zur Auslagerung der Objekterzeugung sind sogenannte Factories gedacht. Sie nehmen alle nötigen Daten entgegen und geben das gefragte Objekt zurück.

\subsection{Repository}

Eine Grundfunktion von allen Anwendungen stellt die Speicherung und das Laden von Daten dar. Mithilfe von Repositories wird der Datenbankzugriff ermöglicht und orchestriert. In Domain-Driven Design benötigt jedes Aggregate ihr eigenes Repository, da sie unabhängig voneinander geladen werden müssen. Durch diese Zuordnung der Zuständigkeiten wird die konzeptionelle Abhängigkeit der Domain von den Datenbanken getrennt. Die Kommunikation mit einem Repository sollte stets über ein fest definiertes Interface geschehen, damit bei Änderungen der darunterliegenden Datenbanktechnologie der Domainkern unbetroffen bleibt. \\\\

Mithilfe des, in diesem Kapitel erarbeiteten, Wissen wurden die Grundgedanken hinter Designprinzipien, Hexagonaler Architektur und Domain-Driven Design verdeutlicht und bildet somit ein solides Fundament für die Durchführung dieses Projekts. Im folgendem wird die Planungsphase des Proof-of-Concepts erläutert.
















































