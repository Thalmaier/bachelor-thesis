
%% GRUNDLAGEN %% 

\chapter{Grundlagen}

Für das Verständnis des Bachelorthemas werden Kernkompetenzen der Softwareentwicklung vorausgesetzt. Dies betrifft vornehmlich Softwaredesign und Architekturstile. Um nachzuvollziehen, wie eine Architektur die Programmierer bei der Entwicklungsphase unterstützt, muss zunächst festgelegt werden, welche Eigenschaften der Quellcode erfüllen soll, damit dieser positive Qualitätsmerkmale widerspiegelt. Hierzu wurden etablierte Designprinzipien über die Jahre festgelegt. Unter anderem die sogenannten 'SOLID'-Prinzipien, die dazu beitragen Architekturansätze miteinander zu vergleichen und zu bewerten.

\section{SOLID-Prinzipien}

Die SOLID-Prinzipen sollen sicherstellen, dass Software auch mit zunehmendem Funktionsumfang weiterhin testbar, anpassbar und fehlerfrei bleibt \cite{Martin.2000, Martin.2018}. Das weitverbreitete Akronym 'SOLID' steht hierbei für die fünf Designprinzipien:

\textbf{\acrfull{SRP}: } {Jede Softwarekomponente darf laut SRP maximal eine zugehörige Aufgabe erfüllen. Eine Änderung in den Anforderungen erfordert somit die Anpassung in genau einer einzelnen Komponente. Dies erhöht stark die \emph{\Gls{Kohasion}} der Komponente und senkt die Wahrscheinlichkeit von unerwünschten Nebeneffekten bei Codeanpassungen. \cite{Martin.SRP, Martin.2018}}

\textbf{\acrfull{OCP}: } Um sicherzustellen, dass eine Änderung in einer Komponente keine Auswirkungen auf eine andere hat, werden diese als 'geschlossen' gegenüber Veränderungen aber weiterhin 'offen' für Erweiterungen definiert. Der erste Teil des Prinzips kann durch eine Schnittstelle, ein sogenanntes Interface, realisiert werden. Es gilt als geschlossen, da die Implementierungen keine Signaturänderungen der im Interface definierten Methoden vernehmen können. Ansonsten müsste der darauf basierende Code ebenfalls bearbeitet werden. Dennoch können weiterhin Modifikationen durch das Vererben von Klassen oder die Einbindung von neuen Interfaces stattfinden. Dies wird als 'offen' im Sinne des OCPs betrachtet. \cite{Martin.2018, Meyer.2009}

\textbf{\acrfull{LSP}: } {Eine wünschenswerte Eigenschaft der Vererbung ist, dass eine Unterklasse S einer Oberklasse T die Korrektheit einer Anwendung nicht beeinflusst, wenn ein Objekt vom Typ T durch ein Objekt vom Typ S ersetzt wird. Dadurch wird die Fehleranfälligkeit bei einer Substitution im Code erheblich reduziert und der Client kann sichergehen, dass die Funktionalität auch weiterhin den erwarteten Effekt hat. Da sich das LSP mit der Komposition von Klassen beschäftigt, ist es für die nachfolgende Architekturanalyse vernachlässigbar. \cite{Martin.2018, Liskov.1994}}

\textbf{\acrfull{ISP}: } {Der Schnitt von Interfaces sollte so spezifisch und klein wie möglich gehalten werden, damit Clients nur Abhängigkeiten zu Funktionalitäten besitzen, welche sie wirklich benötigen. Dadurch wird die Wiederverwendbarkeit und Austauschbarkeit der Komponenten gewährleistet. \cite{Martin.2018}\cite[S. 135ff.]{Martin.2003}}

\textbf{\acrfull{DIP}: } {Module sollten so unabhängig wie möglich voneinander genutzt werden können. Dadurch wird eine erhöhte Testbarkeit und Wiederverwendbarkeit ermöglicht. Das zweiteilige DIP ist von zentraler Bedeutung für eine stabile und flexible Software. Hierbei sollen konzeptionell höhere Komponenten nicht direkt auf darunterliegende Ebenen angewiesen sein, sondern die Kommunikation zwischen ihnen über Interfaces geschehen. Dies erlaubt die Abstraktion von Funktionsweisen und löst die direkten Abhängigkeiten zwischen Modulen auf. Weiterhin wird festgelegt, dass Interfaces nicht an ihre Implementierungen gekoppelt werden sollten, sondern auf deren Abstraktionen beruhen \cite{Martin.1996, Martin.2018}. Dadurch sind die Abhängigkeiten invertiert, was beispielhaft die Anwendung von \emph{\Gls{DI}} ermöglicht \cite{Fowler.2004}.}


\section{Architekturmuster}

Eine Softwarearchitektur beschreibt die grundlegende Struktur der Module, ihre Relationen zueinander und die Art der Kommunikation zwischen den Modulen. Die Wahl der verwendeten Architektur beeinflusst somit die komplette Applikation und ihre Qualitätsmerkmale. Das zu bevorzugende Design einer Anwendung ist gekoppelt an die Anwendungsfälle und ihre Anforderungen. 

In diesem Projekt soll ein Backend-Service erstellt werden, welcher mit den vorgelagerten Systemen über \emph{\acrshort{HTTP}} und \emph{\acrshort{REST}} kommuniziert, wodurch die Auswahl der Architekturen beschränkt wird. Ansätze wie Peer-to-Peer, welche eine Kommunikation zwischen zwei gleichberechtigten Knoten bereitstellen, sind somit in diesem Anwendungsgebiet nur bedingt vertreten. Etablierte Architekturen für Backend-Software, welche die Businessprozesse als Kern der Applikation halten, werden hingegen genauer untersucht. Die Schichtenarchitektur und Hexagonale Architektur werden als Grundlage für das Projekt herangezogen. Im folgenden Abschnitt werden beide Stile untersucht und anhand ihrer Tauglichkeit für eine Checkout-Software bewertet. Dabei wird hinterfragt, in wie fern Entwickler bei der Umsetzung der SOLID-Prinzipien unterstützt werden.

\subsection{Schichtenarchitektur}

In einer Schichtenarchitektur werden die Softwarekomponenten in einzelne Schichten eingeteilt. Die Anzahl der Schichten kann je nach Anwendungsfall variieren, liegt jedoch meist zwischen drei und vier Ebenen. Eine verbreitete Variante beinhaltet die Präsentations-, Business- und Datenzugriffsschicht. Dadurch wird eine Trennung der Verantwortlichkeiten erzwungen \cite[S. 185]{Buschmann.2011}. Der Kontrollfluss der Applikation fließt hierbei stets von einer höheren Schicht in eine tiefer gelegene oder innerhalb einer Ebene zwischen einzelnen Komponenten. Ohne eine konkrete Umkehrung der Abhängigkeiten ist der Abhängigkeitsgraph gleichgerichtet zum Kontrollflussgraph. \cite[S. 17ff.]{Fowler.2011} Der beschriebene Aufbau einer solchen Architektur ist in Abbildung \ref{fig:Schichtenarchitektur} beispielhaft dargestellt. 

\begin{figure}[H]
	\centering
	\large
	\includesvg[width=0.47\textwidth]{svg/Schichtenarchitektur.svg}
	\caption{Beispielhafte Darstellung einer Drei-Schichtenarchitektur}
	\label{fig:Schichtenarchitektur}
\end{figure}

\pagebreak

Wesentliche Ziele einer Schichtenarchitektur sind die Entkopplung der einzelnen Schichten voneinander und das Erreichen von geringen Abhängigkeiten zwischen den Komponenten \cite[S. 17]{Fowler.2011}. Dadurch sollen Qualitätseigenschaften wie Testbarkeit, Erweiterbarkeit und Flexibilität erhöht werden. Dank des simplen Aufbaus gewann dieser Architekturstil an großer Beliebtheit. Weitere bewertende Aspekte einer solchen Softwarestruktur ergeben sich aus der Analyse der SOLID-Prinzipien:

\textbf{\acrlong{SRP}:} Durch die Schichteneinteilung wird die natürliche Einhaltung des \acrshort{SRP}s unterstützt, da eine Komponente zum Beispiel keine Businesslogik und zugleich Funktionen der Datenzugriffsschicht implementieren kann. Nichtsdestotrotz ist eine vertikale Trennung innerhalb einer Schicht nicht gegeben, daher können weiterhin Klassen mehrere, konzeptionell verschiedene Aufgaben entgegen des SRPs erfüllen. 

\textbf{\acrlong{OCP} \& \acrlong{ISP}:} Um die einzelnen Schichten zu entkoppeln, kann die Kommunikation zwischen den Ebenen durch Schnittstellen geschehen. Dadurch wird eine grundlegende Befolgung des \acrshort{ISP} erreicht. Das \acrlong{OCP} soll hierbei helfen, dass Änderungen an den Schnittstellen und ihren Implementierungen die Funktionsweise nicht beeinflussen, auf denen tieferliegende Schichten basieren. Die logische Zuteilung dieser Interfaces ist entscheidend, um eine korrekte Anwendung des \acrlong{DIP}s zu gewährleisten. 

\textbf{\acrlong{DIP}:} Meist wird bei webbasierten CRUD-Applikationen eine Schichtenarchitektur verwendet. \acrshort{CRUD} steht im Softwarekontext für '\textbf{C}reate \textbf{R}ead \textbf{U}pdate \textbf{D}elete' und meint Anwendungen, die Daten mit geringer bis keiner Geschäftslogik erzeugen, bearbeiten und löschen \cite[S. 381]{Martin.1980}. Im Kern einer solchen Software liegen die Daten selbst. Dabei werden Module und die umliegende Architektur angepasst, um die Datenverarbeitung zu vereinfachen. Die Abhängigkeiten in einer Schichtenarchitektur richten sich daher oft von der Businessschicht zur Datenzugriffsschicht \cite{Layered.SOLID}. Bei einer Applikation, die als Hauptbestandteil Businesslogik enthält, sollte hingegen die Abhängigkeiten zur Businessschicht fließen. Daher muss während des Entwicklungsprozesses stets die konkrete Einhaltung des DIPs beachtet werden, da entgegen der intuitiven Denkweise einer Schichtenarchitektur gearbeitet wird. 

Folglich bietet dieser Architekturansatz zwar einerseits einen hohen Grad an Simplizität, jedoch andererseits sind die SOLID-Prinzipien nur gering im Grundaufbau wiederzuerkennen. 

\pagebreak

\subsection{Hexagonale Architektur}

Durch architektonische Vorgaben können Entwickler zu besserem Softwaredesign gezwungen werden, ohne dabei die Implementierungsmöglichkeiten einzuengen. Dieser Denkansatz wird in der von Alistair Cockburn geprägten Hexagonalen Architektur angewandt, indem eine klare Struktur der Softwarekomposition vorgegeben wird. Der Aufbau wird in Abbildung \ref{fig:HexagonaleArchitektur} veranschaulicht. \\

\begin{figure}[H]
	\centering
	\includesvg[width=0.60\textwidth]{svg/HexagonaleArchitektur.svg}
	\caption{Grundstruktur einer Hexagonalen Architektur \cite[angelehnt an][]{hgraca.2017}}
	\label{fig:HexagonaleArchitektur}
\end{figure}

\vspace{0.3cm}

Hierbei existieren drei Bereiche in denen die Komponenten angesiedelt werden können: \cite{Cockburn.Hexagonal, Griffin.2021b}  

\textbf{Ports:} Die gesamte Kommunikation zwischen den Adaptern und dem Applikationskern findet über sogenannte \emph{Ports} statt. Diese dienen als Abstraktionsschicht, sorgen für Stabilität und schützen den Kern vor Codeänderungen anhand des \acrlong{OCP}s. Realisiert werden Ports meist durch Interfaces, welche hierarchisch dem Zentrum zugeteilt und deren Design durch diesen maßgeblich bestimmt werden. Somit erfolgt die Einhaltung des \emph{\acrlong{DIP}s}, wodurch die Applikationslogik von externen Systemen und deren konkreten Implementierungen abgekoppelt wird. Dies verringert die Abhängigkeiten zwischen Komponenten und erhöht zugleich die Testbarkeit der Anwendung. \cite{philipbrown.2014}

\pagebreak

\textbf{Adapter:} Die Komponenten zwischen externen Systemen und der Geschäftslogik heißen Adapter. Ein \emph{primärer Adapter} wird durch das externe System angestoßen, welcher daraufhin den Steuerfluss durch einen wohldefinierten Port in den Applikationskern trägt. Zu diesen externen Systemen zählen unter anderem Benutzerinterfaces, Kommandokonsolen sowie Testfälle. Andererseits bilden alle Komponenten, bei denen der Steuerfluss vom Applikationskern zu den externen Systemen gerichtet ist, die Gruppe der \emph{sekundären Adapter}. So entsteht der Impuls im Vergleich zu den primären Adaptern nicht außerhalb der Applikation, sondern innerhalb. Die von den sekundären Adaptern angesprochenen Systeme können beispielsweise Datenbanken, Message-Broker und weitere Nachbarapplikation sein.  \cite{hgraca.2017}

\textbf{Applikationskern:} Letztendlich werden alle übrigen Module im Applikationskern erschlossen. Diese beinhalten Businesslogik und sind mithilfe der von ihnen zur Verfügung gestellten Ports von konkreten Implementierungen entkoppelt. \\

Zum Verdeutlichen der Funktionsweise einer hexagonalen Applikation wird ein simpler Anwendungsfall durchgespielt. Konkret sollen von Clients übertragene Daten in einer Datenbank gespeichert werden. Ein Webclient spricht eine Schnittstelle des Systems mit den Nutzdaten an, wodurch er den Steuerfluss der Applikation initiiert. Die Schnittstelle ist den primären Adaptern zugeteilt und erledigt Aufgaben wie Authentifizierung, Datenumwandlung und erste Fehlerbehandlungen. Über einen entsprechenden Port wird der Kern mit den übergebenen Daten angestoßen. Innerhalb des Applikationszentrums werden alle business-relevanten Aufgaben erfüllt. Darunter fallen das logische Überprüfen der Werte anhand von Businessrichtlinien, Erstellen neuer Daten und die Steuerung des Entscheidungsflusses. In diesem Anwendungsfall sollen die Nutzdaten in einer Datenbank abgespeichert werden. Dementsprechend wird aus dem Anwendungskern über einen weiteren Port ein sekundärer Adapter aufgerufen, welcher die dauerhafte Speicherung in der Datenbank übernimmt. Anhand des Aufbaus einer Hexagonalen Architektur kann hinsichtlich der SOLID-Prinzipien im Vergleich zur Schichtenarchitektur folgendes Fazit formuliert werden:

\textbf{\acrlong{SRP}: } {Durch die Struktur wird eine strengere konzeptionelle Trennung der Verantwortlichkeiten ermöglicht. Dies wirkt sich positiv auf die Einhaltung des \acrlong{SRP}s aus.}

\textbf{\acrlong{OCP} \& \acrlong{ISP}: } {Als Folge der Nutzung von Ports zwischen dem Applikationskern und dem außenstehenden Komponenten ist die Anwendung der beiden Prinzipien erleichtert und teilweise automatisch gegeben. Die Applikation profitiert von erhöhter Stabilität und Kohäsion. }

\textbf{\acrlong{DIP}: } {In einer Hexagonalen Architektur ist das \acrlong{DIP} fest durch die vorgeschriebene Komposition verankert. Dadurch wird das Austauschen von Komponenten ermöglicht, ohne dabei den Businesskern verändern zu müssen. Dies entkoppelt nicht nur den wichtigsten Bestandteil der Software, sondern fördert schlussfolgernd auch die Testbarkeit. Durch eine native Invertierung der Abhängigkeiten gewinnt somit die Applikation viele positive Qualitätsmerkmale. \cite{Alliaume.2018, Martinez.2021}}

So ergibt sich eine natürliche Einhaltung der SOLID-Prinzipien, wobei der Applikationskern in den Vordergrund gerückt wird. Anzumerken ist, dass erfahrene Entwickler ebenfalls mit einer Schichtenarchitektur ein gleiches Maß an Softwarequalität erzielen können, sofern die Designprinzipien diszipliniert eingehalten werden, da bei genauer Betrachtung eine Hexagonale Architektur äquivalent mit einer dreiteiligen Schichtenarchitektur mit erzwungenem \acrlong{DIP} ist \cite{Seemann.2013} \cite[S. 125ff.]{Vernon.2015}. 


\section{Domain-Driven Design}

In der Entwicklungsphase von komplexer Software besteht stets die Gefahr zu einem sogenannten 'Big Ball of Mud' zu verschmelzen, weil die steigende Anzahl von Anforderungen und Codeänderungen die Übersichtlichkeit des Sourcecodes beeinträchtigt. Die bestehende Architektur wird unübersichtlich, Entstehungschancen für Bugs erhöhen sich und die Businessanforderungen sind überall in der Anwendung verteilt wiederzufinden. Somit kann die Wartbarkeit der Software nicht mehr gewährleistet werden und ihre Langlebigkeit ist stark eingeschränkt. \cite{bbom.1999} Die oben analysierten Architekturstile können bei strikter Umsetzung diese Risiken minimieren, jedoch bestimmen sie nur begrenzt, wie das zugrundeliegende Datenmodell und die damit verbundenen Komponenten gestaltet werden sollen. In dem Buch \citetitle{Evans.2011} entwickelte Eric Evans im Jahr 2003 zu diesem Zweck \acrlong{DDD}, kurz \acrshort{DDD}. Der Buchtitel beschreibt bereits den Hauptgedanken hinter Domain-Driven Design. Liegen die Businessanforderungen im Herzen der Software, sollte dementsprechend auch ihre Implementierung zentral verankert sein. Der Applikationskern stellt somit den 'lebenden' Teil der Anwendung dar. Die verbleibenden Komponenten dienen zur Unterstützung der Businesslogik, indem sie benötigte Dienste dem Kern bereitstellen. Die Businessanforderungen werden somit in DDD strukturell aus dem Quelltext hervorgehoben. Das Datenmodell spiegelt zudem die Sprache der Geschäftsprozesse wider, wodurch die Realisierung der Applikationslogik erleichtert wird. Vor allem Anwendungen mit komplexen Entscheidungssträngen und vielen jederzeit gültigen Konditionen können dadurch übersichtlich implementiert werden. Zu diesem Zweck definiert Domain-Driven Design einige Vorgehensweisen, Richtlinien und Entwurfsmuster, welche in diesem Kapitel erläutert werden. \cite{Evans.2011, Vernon.2015}

\subsection{Unterteilung der Problemebene in Domains und Subdomains}

Der Problemraum eines Projektes spannt in Domain-Driven Design eine \emph{Domain} auf \cite[S. 56]{Vernon.2015}. Dieser Bereich umfasst logisch zusammengehörige Verantwortlichkeiten und Businessprozesse. Anfangs sollte die Domain anhand einer ausführlichen Umfeldanalyse definiert werden, damit alle Aspekte des Problemraums und seine Abhängigkeiten beleuchtet werden. Innerhalb einer Domain liegen die dazugehörigen \emph{Subdomains}. Eine Subdomain repräsentiert einen kleineren, spezifischeren Teil der Domain, wodurch der Problemraum in mehrere Bereiche unterteilt wird. Sie helfen im nachfolgenden Schritt bei der Formulierung des Lösungsraumes. Zur Bestimmung der Subdomains werden die Verantwortlichkeiten stets aus Businesssicht betrachtet und technische Aspekte vernachlässigt. Der Domainumfang ist dabei entscheidend. Sollte dieser zu groß geschnitten sein, sind die Subdomains ebenfalls zu weitreichend. Das gefährdet die Kohäsion der Lösungsebene und somit der Software. Über den Verlauf der Entwicklungsphase könnten aufgrund dessen architektonische Konflikte auftreten. Enthält eine Subdomain mehrere logisch unabhängige Aufgaben, kann sie in kleinere Subdomains weiter unterteilt werden. Für einen Domain-Driven Ansatz ist es entscheidend die Definitionsphase gewissenhaft durchzuführen, damit eine stabile Grundlage für die Umsetzung des Projekts geschaffen werden kann.

\pagebreak

\subsection{Bounded-Contexts und ihre Ubiquitous Language}

Als Ausgangspunkt für die Bestimmung der Lösungsebene dienen die sogenannten Bounded-Contexts \cite[S. 57]{Vernon.2015}, welche eine oder mehrere Subdomains umfassen und ihre zugehörigen Verantwortlichkeiten bündeln. Wie es in der Praxis häufig der Fall ist, können Subdomains und Bounded-Contexts durchaus identisch sein \cite[S. 57]{Vernon.2015}. In jedem Bounded-Context sollte maximal ein Team tätig sein, um Kommunikationsprobleme zu vermeiden und eine klare Zuteilung der Kompetenzen zu gewährleisten \cite{Brandolini.2021}. Jeder Bounded-Context besitzt zudem eine zugehörige \emph{Ubiquitous Language} \cite[S. 62]{Vernon.2015}. Sie wird als wichtiger Bestandteil während der Projektplanung festgelegt und definiert Begriffe, welche durch die \emph{\Gls{Stakeholder}} und das Business verwendet werden. Dadurch können Missverständnisse in der Kommunikation zwischen dem Business und den Entwicklern vorgebeugt und eventuelle Inkonsistenzen aufgedeckt werden \cite[S. 336f.]{Evans.2011}. Der größte Vorteil ergibt sich allerdings, sobald auch das Datenmodell diese Sprache wiedergibt. Entities können als Nomen dargestellt, Funktionen können als Verben definiert und Aktionen können als Events abgebildet werden, wodurch die Businessprozesse auch im Quelltext wiederzufinden sind. Folglich wird die Verständlichkeit und Wartbarkeit der Software \cite[S. 24ff.]{Evans.2011} gesteigert. Zudem werden Entwickler bei der Umsetzung von Test- und Anwendungsfällen unterstützt, da ihre textuellen Definitionen auf das Datenmodell übertragbar sind. Zu beachten ist, dass die \emph{Ubiquitous Language} nur innerhalb eines Bounded-Context Gültigkeit hat \cite[S. 62]{Vernon.2015}. Beispielhaft kann der Begriff 'Kunde' in einem Onlineshop einen zivilen Endkunden, jedoch im Wareneingang eine Lieferfirma beschreiben. Daher ist bei der Kommunikation zwischen Teams in unterschiedlichen Subdomains zu berücksichtigen, dass Begriffe eventuell verschiedene Bedeutungen besitzen.

Die Domains, Subdomains, Bounded-Contexts und ihre Kommunikation zueinander wird durch eine Context-Map dargestellt. Diese ist ein wichtiges Artefakt der Definitionsphase und kann als Werkzeug zur Bestimmung von Verantwortlichkeiten und der Einteilung neuer Anforderungen genutzt werden. Sollte eine eindeutige Zuteilung von Funktionalitäten nicht möglich sein, spricht dies für die Entstehung eines neuen Bounded-Contexts und eventuell einer Subdomain. Wie eine Software Anpassungen erlebt, entwickelt sich gleichermaßen die Context-Map stetig weiter. \cite[S. 87ff]{Vernon.2015} Zur Veranschaulichung wurde in Abbildung \ref{fig:Context-Map-Example} das Personalwesen eines Unternehmens als Domain ausgewählt und in Subdomains bzw. Bounded-Contexts aufgeteilt. Abhängig von der Unternehmensgröße und -strategie können die Bounded-Contexts auch umfassender oder feingranularer ausfallen.

\begin{figure}[H]
	\vspace{0.2cm}
	\centering
	\footnotesize
	\includesvg[width=0.85\textwidth, height=0.85\textwidth]{svg/ExampleDomainV2.svg}
	\caption{Beispiel einer Context-Map anhand des Personalwesens einer Firma}
	\label{fig:Context-Map-Example}
\end{figure}

\subsection{Kombination von Domain-Driven Design und Hexagonaler Architektur}

Innerhalb eines Bounded-Contexts wird die grundlegende Architektur durch das zugehörige Team bestimmt. Diese kann sich je nach Sachverhalt des jeweiligen Anwendungsgebietes stark zwischen den Bounded-Contexts unterscheiden. Beliebte Modellierungs- und Designstile in Verbindung mit DDD sind unter anderem Microservices, \emph{\acrfull{CQRS}}, Event-Driven Design, Schichtenarchitektur und Hexagonale Architektur \cite[S. 113ff.]{Vernon.2015}. In den vorhergehenden Unterkapiteln wurden bereits die Vorzüge und Nachteile der zwei zuletzt genannten Architekturen erläutert. Auf Basis der Analyse wird generell für komplexere Software eine Hexagonale Architektur bevorzugt. Zudem steht im Zentrum von Domain-Driven Design und Hexagonaler Architektur das Domain-Modell, wodurch die Software an Kohäsion und Stabilität gewinnt. Die Kombination beider Ansätze ermöglicht es, bei häufigen technischen Neuerungen und komplexen Businessanforderungen weiterhin eine anpassbare, testbare und übersichtliche Software zu implementieren. Auf ein solches solides Grundgerüst wird mithilfe der Kenntnisse über den Bounded-Context das Domain-Modell gesetzt. Es umfasst sowohl die Datenhaltung als auch das zugehörige Verhalten, wie zum Beispiel die Überprüfung von Richtlinien, Modifikation von Attributen oder ihre dauerhafte Speicherung. Für diesen Zweck existieren in Domain-Driven Design mehrere Arten von Komponenten, welche anhand ihrer Verantwortlichkeiten unterschieden werden. Die korrekte Zuordnung der Klassen zu ihren Rollen ist entscheidend für einen skalierbaren Aufbau. Daher wird in den folgenden Unterkapiteln ein zentraler Überblick der einzelnen Bestandteile aufgeführt.

\subsection{Value Object}

Die Value Objects bilden eine Möglichkeit zusammengehörige Daten zu gruppieren. Entscheidend ist hierbei die Frage, durch welche Eigenschaft der Zusammenschluss identifiziert wird. Die Identität eines Value Object wird alleinig durch die Gesamtheit ihrer Attribute bestimmt. Somit sind zwei Value Objects mit gleichen Werten auch identisch und miteinander austauschbar ohne die Funktionalität der Software zu beeinflussen \cite[S. 227]{Vernon.2015}. Aus diesem Grund gelten Value Objects als \emph{\gls{immutable}}, da sie selbst keinen Werteverlauf besitzen \cite[S. 99]{Evans.2011}. Eine Neuzuweisung der Attribute ist deshalb nicht möglich. Stattdessen wird die Referenz auf eine andere, angepasste Instanz der Klasse umgesetzt \cite[S. 226]{Vernon.2015}. Dies gilt als ein erstrebenswertes Designmuster, da unveränderbare Objekte eine erhöhte Wiederverwendbarkeit ermöglichen und unerwünschte Seiteneffekte vermieden werden \cite[S. 228f.]{Vernon.2015}. Folglich sind sie aufgrund des fehlenden Lebenszyklus lediglich eine Momentaufnahme des Applikationszustandes.

\textbf{Beispiel:} In den meisten E-Commerce Bounded-Contexts sind alleinig die konkreten Werte eines \emph{Preises}, wie Bruttobetrag, Nettobetrag und Mehrwertsteuer relevant, weshalb dieser meist als Value Object angesehen wird. Sollten Preise die gleichen Wertebelegungen besitzen, gelten sie dementsprechend als identisch. Bei einer Aktualisierung eines Preises, kann das vorherige Objekt gelöscht und durch einen Preis mit den neuen Werten ersetzt werden. Ist es notwendig, den Werteverlauf des Preises über eine Zeitspanne zu verfolgen, wird oftmals eine ID innerhalb der Datenstruktur hinterlegt. Die Identität ist dadurch nur noch von der ID abhängig, nicht mehr von den Werten. Die Definition eines Value Objects trifft auf die Klasse nicht mehr zu und ein Design als Entity ist zu bevorzugen.  

\pagebreak

\subsection{Entity}

Im Gegenzug zu einem Value Object wird eine Entity nicht durch den Zusammenschluss ihrer Werte identifiziert, sondern enthält ein vordefiniertes Set an \gls{immutable} Attributen, welche ihre Eindeutigkeit bestimmen \cite[S. 94]{Evans.2011}. Auch nach dem Aktualisieren ihrer Informationen bleibt die ursprüngliche Identität bestehen. Demzufolge gelten die Attribute einer Entity als veränderlich und besitzen ihren eigenen Lebenszyklus, auch wenn dieser nicht explizit abgespeichert werden muss \cite[S. 172]{Vernon.2015}. In einer Entity werden Businessanforderungen, die sich auf enthaltenen Daten beziehen, direkt implementiert und ihre \emph{\Gls{Invariante}n} sichergestellt \cite[S. 208f.]{Vernon.2015}. Dadurch wird eine hohe Kohäsion erzeugt und entsprechend des \emph{\Gls{Information-Expert-Prinzip}s} korrekt verankert.

\textbf{Beispiel:} Ein \emph{Kunde} innerhalb eines Domainmodells ist meist eine Entity. In vielen Bounded-Contexts wird ein Kunde durch eine eindeutige ID ausgewiesen. Somit sind zwei Kunden mit identischen Namen dennoch nicht die gleichen Personen. Sollte der Name einer Person angepasst werden, ist ihre Identität weiterhin äquivalent zur vorhergehenden. Invarianten, wie die korrekte Formatierung der hinterlegten E-Mail, können beispielsweise direkt bei der Aktualisierung überprüft werden.


\subsection{Aggregate}

Innerhalb des Bounded-Contexts ist ein Aggregate der Verbund aus Entities und Value Objects, welcher von außen als eine Einheit wahrgenommen wird. Hierbei findet die Gruppierung anhand ihrer logischen Zusammengehörigkeit und Verantwortungen statt. Externe Komponenten dürfen beim Aufruf eines Aggregates nur auf das sogenannte Aggregate Root zugreifen und enthaltene Objekte nicht direkt referenzieren. Das Aggregate Root ist demzufolge eine Schnittstelle zwischen dem Aggregate und der Außenwelt. \cite[S. 126f.]{Evans.2011}

\textbf{Beispiel:} Ein mögliches Aggregate im Bereich des Personalmanagements ist ein \emph{Mitarbeiter}, welches Value Objects, wie \emph{Gehalt} und \emph{Abteilung}, beinhaltet. Die Klasse \emph{Mitarbeiter} ist auch zugleich ihr eigenes Aggregate Root. Bei Gehaltsanpassungen wird eine Funktion der Mitarbeiter-Klasse aufgerufen, welche das neue Gehalt durch Austausch des Value Objects einträgt. In diesem Schritt können Invarianten überprüft werden, sodass beispielsweise ein neues Gehalt nicht negativ oder niedriger als das vorgehende ausfallen darf. Abhängig vom jeweiligen Bounded-Context ist der Werteverlauf des Gehaltes eventuell relevant, weshalb die Klasse stattdessen als eine Entity realisiert werden sollte. 

Um die Effektivität von Aggregates zu gewährleisten, wurden in Domain-Driven Design einige Einschränkungen und Richtlinien beschlossen. Businessanforderungen bzw. Invarianten von enthaltenen Objekten müssen stets vor und nach einer Transaktion erfüllt sein. Dadurch sind die Grenzen der Aggregates durch den minimalen Umfang der transaktionalen Konsistenz ihrer Komponenten gesetzt \cite[S. 354]{Vernon.2015}. Als Folge dessen, wird immer das komplette Aggregate aus der Datenbank geladen und zurückgeschrieben. Große Aggregates leiden aus diesem Grund an reduzierter Skalierbarkeit und Performance, da die Datenmenge und notwendigen Operationen auf Seiten der Datenbank Last verursacht \cite[S. 355]{Vernon.2015}. Weiterhin sollte pro Transaktion jeweils nur ein Aggregate bearbeitet werden \cite[S. 354]{Vernon.2015}. Dies schränkt umfangreiche Aggregates durch fehlende Parallelität weiter ein. Unter Beachtung der letzten Regel wäre es nicht möglich das Gehalt und die Abteilung der Mitarbeiter-Klasse durch zwei unterschiedliche Personalmitarbeiter zeitgleich anzupassen. Eine der beiden Transaktionen würde sonst auf einen veralteten Stand operieren und müsste zur Vermeidung eines \Gls{Lost Update}s zurückgerollt werden. Sollte ein Anwendungsfall die Anpassung zweier Aggregates benötigt, kann das Konzept der Eventuellen Konsistenz angewandt werden. Dabei entsteht kurzzeitig ein inkonsistenter Stand der Daten, da zwei Transaktionen zeitversetzt gestartet werden. In vielen Fällen ist ein Verzug der Konsistenz aus Sicht der Businessanforderungen akzeptabel und damit eine mögliche Alternative für die Zusammenführung der beiden Aggregates. \cite[S. 364]{Vernon.2015}

\pagebreak

\subsection{Applicationservice}

Aufgaben, welche kein Domainwissen erfordern, werden in den Applicationservices realisiert. Ihre Aufgabe ist die Bereitstellung von notwendigen Dienstleistungen zur Abwicklung der Businesslogik \cite{Gorodinski.2012}. Dazu gehört das Management von Transaktionen, simple Ablaufsteuerung und Aufrufe anderer Services oder Aggregate Roots. Somit dürfen sie keine Businessanforderungen enthalten oder Invarianten überprüfen, da dies in den Zuständigkeitsbereich der Domainservices fällt \cite[S. 267]{Vernon.2015}. Die Namensgebungen der Klassen und ihrer Funktionen stammen meist aus Begriffen der Ubiquitous Language \cite[S. 105]{Evans.2011}. Um Nebeneffekte ausschließen zu können und Parallelität zu ermöglichen, müssen die Applicationservices zustandslos designt werden \cite[S. 105]{Evans.2011}.

\subsection{Domainservice}

Soweit anwendbar, werden Businessanforderungen direkt in den zuständigen Entities oder Value Objects umgesetzt. Allerdings existieren Fälle, in denen keine klare Zuteilung der Aufgaben möglich ist. Dies kann beispielsweise auftreten, wenn sich der Prozess über zwei oder mehr Aggregates spannt. In diesem Fall wird die Funktionalität in einem Domainservice ausgelagert. Sollte die auszuführende Logik Abhängigkeiten zu anderen Services besitzen oder die Kohäsion der Entity bzw. des Value Object verringert werden, ist dies ein weiterer Grund für die Nutzung eines Domainservices. Analog zu den Applicationservices werden sie zustandslos implementiert und stammen aus der Ubiquitous Language. Sie unterscheiden sich lediglich darin, dass es für Domainservices erlaubt ist, Businesslogik umzusetzen und Invarianten zu beinhalten. \cite[S. 268]{Vernon.2015}

\subsection{Factory}

Die wiederholte Erstellung von komplexen Objekten kann unnötigen Platz im Quelltext einnehmen und die Übersichtlichkeit einschränken, vor allem wenn zusätzliche Services zu diesem Zweck benötigt werden. Der Effekt wird verstärkt, wenn das Codefragment an verschiedenen Stellen auftritt. Zur Auslagerung der Objekterzeugung sind sogenannte Factories vorgesehen. Sie nehmen alle nötigen Daten entgegen und geben das gefragte Objekt zurück. Dadurch wird auch die Kohäsion der Applikation gestärkt. \cite[S. 137f.]{Evans.2011}

\subsection{Repository}

Eine Grundfunktion von Applikationen ist das Speichern und Laden von Daten. Repositories ermöglichen und orchestrieren hierbei den Datenbankzugriff \cite[S. 151]{Evans.2011}. In Domain-Driven Design benötigt jedes Aggregate ihr eigenes Repository, da sie unabhängig voneinander geladen werden müssen \cite[S. 401]{Vernon.2015}. Durch diese Zuordnung der Zuständigkeiten werden die konzeptionellen Abhängigkeiten der Domain von den Datenbanken getrennt. Die Kommunikation mit einem Repository sollte über ein fest definiertes Interface geschehen, damit bei Änderungen der darunterliegenden Datenbanktechnologie der Domainkern unbetroffen bleibt \cite[S. 152]{Evans.2011}. \\

Die erarbeiteten Grundgedanken von Domain-Driven Design, Hexagonaler Architektur und der SOLID-Prinzipien bildenden Rahmen für die Durchführung des Projekts. Im Folgenden wird diese Basis in der Planungsphase erweitert und die Checkout-Domain erschlossen.
