\chapter{Design möglicher Aggregationsschnitte }

Ein Domainmodell kann unterschiedlich gestaltet werden. Ebenfalls betrifft dies den Schnitt der Aggregates. Verschiedene Schnitte genießen verschiedene Vor- und Nachteile. In diesem Kapitel werden mehrere mögliche Aufteilungen untersucht und durch verschiedene Kriterien bewertet. Diese Kriterien umfassen unter anderem Performance, Komplexität, Konsistenz, Parallelität, Relevanz und Anwendbarkeit im Bezug auf den Bounded Contexts des Checkouts.

\section{Ein zusammengehöriges Basket-Aggregate als initiales Design}

Das Design eines großen Aggregats fällt Entwicklern meist natürlich leichter. Eine einzelne zusammenhängende Struktur, durch welche Daten einfach bearbeitet und Invarianten überprüft werden können. Daher hält sich die Komplexität bei diesem Aggregationsschnitt weitestgehend in Grenzen. Vor allem müssen kaum Überlegungen über transaktionale Konsistenz getroffen werden, da die Grenzen der Transaktion all umspannend ist. Die erste Variante des Proof-Of-Concepts wurde mit diesem Design im Gedanken entwickelt und stellt das Grundgerüst für alle folgenden Konzepte dar. Zur vereinfachten Referenz auf die einzelnen Umsetzungsvarianten wird das Design, welches einen großen Basket zugrundeliegend hat, als '\emph{Variante A}' betitelt.


\subsection{Performance von unterschiedlich großen Aggregates im Vergleich}

%TODO: Lazy loading
Als Konsequenz eines großen Aggregates ergibt sich, dass immer das ganze Aggregate geladen werden muss, da auf darunterliegende Datenstrukturen nur durch das Aggregate Root zugegriffen werden darf. Für die Aktualisierung einer Entity tief im Aggregat müssen alle anderen Daten ebenfalls geladen werden. Die Auswirkungen dieser Aussage kann auf Datenbankebene anhand von Lazy-Loading oder durch Einsatz einer dokumentbasierten Datenbank eingeschränkt werden. Generell gilt, dass große Aggregates aus Sicht der Performance langsamer arbeiten als kleinere. Diese Aussage ist allerdings mit Vorsicht zu genießen und kann je nach Anwendungsgebiet sogar gegensätzlich ausfallen. In diesem Unterkapitel wird die diese Richtlinie anhand unseres Bounded Contexts analysiert.

Wie oben erwähnt, ermöglicht ein kleinerer Aggregationsschnitt das unabhängige laden und bearbeiten der Aggregates. In Betrachtung der Anwendungsfälle können die Operationen in drei große Gruppen umfasst werden. Anfragen, welche Value Objects im Basket bearbeiten stellt die erste Ansammlung dar. Diese würden unnötige Daten laden, da nur der Basket mit möglichst wenig Value Objects relevant ist. Ebenfalls gilt dies für die Anfragen, welche BasketItems oder den PaymentProcess anpassen, weil sie den ganzen Basket laden anstatt nur die wirklich benötigten Daten.

Wird die \emph{Variante A} unterteilt in Basket-, Payment und BasketItem-Aggregate (\emph{Variante B}) können diese somit unabhängig voneinander geladen und bearbeitet werden. Ohne Beachtung, welche Auswirkungen dieses neu überlegte Design auf andere Faktoren hat, ist eine Performanceverbesserung anhand ersten Überlegungen zu erwarten. Die vermeintlich gewonnene Performance wird allerdings aufgrund mehrerer Umständen verringert. Eine kurze Übersicht über diesen neuen Aggregationsschnitt bietet Abbildung \ref{fig:VarB}.

\begin{figure}[htbp]
	\centering
	\includesvg[inkscapelatex=false, width=0.80\textwidth]{svg/VarB.svg}
	\caption{Aggregationsschnitt der Variante B}
	\label{fig:VarB}
\end{figure}

\subsubsection{Invarianten über Aggregatsgrenzen hinweg}

Wird dem Warenkorb ein neuer Artikel hinzugefügt hat dies zu Folge, dass nicht nur ein neues Item angelegt, sondern auch der Baskets neu berechnet werden muss. Sofern eine Aggregatstrennung zwischen Basket und BasketItem vorliegt, muss dennoch der ganze Basket geladen werden, andernfalls ist es nicht möglich den Gesamtpreis zu ermittelt. Innerhalb eines Checkout-Contexts existieren viele dieser Businessanforderungen, welche mehrere Objekte benötigen, um angewandt zu werden. Zudem ist es gegen die grundlegenden Bestimmungen eines Aggregates, dass eine Anfrage bzw. Transaktion zwei oder mehrere Aggregate bearbeiten. Dieser Anwendungsfall hätte eine Speicherung eines neuen BasketItems und die Aktualisierung des CalculationResults des Baskets zufolge. Schlussfolgernd wäre eine solche Operation nicht erlaubt ohne Verwendung von eventueller Konsistenz. Um genauer zu bestimmen, welche tatsächliche Performance erzielt werden kann durch kleinere Aggregates am konkreten Design der \emph{Variante B} müssen die Anzahl der tatsächlich unabhängig abschließbaren Operationen untersucht werden. Die vorher festgelegten Aktivitätsdiagramme helfen bei dieser Aufgabe.

Ein Abruf eines Baskets kommt einher mit dem Laden aller anderen Aggregates, da die Touchpoints den gesamten Basket benötigen. Dies gilt ebenfalls für alle anderen Anwendungsfälle, welche als Antwort auf ihre Anfrage einen kompletten Basket erwarten. Das Stornieren des Baskets und Setzten der Checkout-Daten ist positiv von dieser Anpassung betroffen. Jedoch ist die Initiierung und Durchführung des Bezahlvorgangs nicht komplett unabhängig abschließbar, da im Nachhinein der Status des Baskets angepasst werden muss. Dadurch entsteht eine Abhängigkeit, welche im Nachhinein erfüllt werden muss und somit zur eventuellen Konsistenz führt. Die größte Anzahl an API-Anfragen beziehen sich auf das Hinzufügen und Bearbeiten von BasketItems und die Verwaltung des Bezahlvorgangs. Letztendlich sind nur eine Bruchzahl der Anwendungsfälle durch einen Umbau der Architektur von Variante A auf Variante B wirklich positiv betroffen.

\subsubsection{Einfluss des Datenbankmodells auf den Aggregationsschnitt}

Das Design einer Software soll stets so weit wie möglich unabhängig von verwendeten Technologien sein. Technologien entwickeln sich weiter, werden durch neuer ersetzt und bringen unnötige Abhängigkeiten in den Quelltext. Theoretisch hat somit eine Beeinflussung der Architektur durch eine externe Komponente einen negativen Effekt auf die Qualität der Software und ihre Wartbarkeit. Dennoch kann in der Praxis dieser Gedanke durchaus Vorteile bergen, welche dieses Vorgehen gerechtfertigt. Folglich wird der Aggregatsschnitt aus Sicht der Datenbank bewertet.

Laut Definition erhält jedes Aggregate seine eigene Tabelle in der darunterliegenden Datenbank. Daher existieren in \emph{Variante B} mindestens die Tabelle für den Basket, BasketItems und PaymentProcess. In \emph{Variante A} kann der PaymentProcess in die gleiche Tabelle wie der Basket geschrieben werden, da eine Eins-zu-Eins Relation vorliegt. Obwohl es nur ein Aggregate gibt, sind dennoch zwei Tabellen für Basket und BasketItem notwendig, da in einer Relationalen Datenbank eine Eins-zu-N Beziehung nicht anders dargestellt werden kann. Demnach muss beim Abruf eines kompletten Baskets in \emph{Variante A} N Joins durchgeführt werden, wobei \emph{Variante B} N+1 Joins benötigt, wobei N die Anzahl der BasketItems entspricht. Dies resultiert in eine schlechtere Performance der \emph{Variante B} zumindest in Bezug der Datenbankabfrage. Wie bereits erwähnt, erwarten eine Vielzahl von Anfragen alle Daten des Baskets zurück und dadurch erhalten wir eine erhöhte Bearbeitungszeit der Anfragen.

%TODO: Collection
Sollte die verwendete Datenbank jedoch einen dokumentbasierten Ansatz verfolgen, gilt vorheriger Absatz nur noch bedingt. Hierbei benötigt \emph{Variante B} weiterhin drei eigene Collections, jedoch kann \emph{Variante A} in einem einzigen Eintrag gespeichert und geladen werden. An sich besitzt der einzelne Datensatz zwar mehr Daten, allerdings hat dies keine Auswirkung auf die Gesamtperformance. Daher würde bei einem Umbau der Aggregate für die meisten Anwendungsfälle eine einzelne Suchanfrage in N+1 Suchanfragen abgewandelt werden. Dies kann bemerkbare Auswirkungen auf die Antwortzeit unserer Applikation haben.

Im ersten Absatz wurde beschrieben, dass eine Technologie keine Auswirkung auf die Architektur haben sollte, konträr dazu ist bei der Betrachtung der Applikationsperformance dies eventuell sinnvoll. Sollte eine relationale Datenbank verwendet werden, hält sich die Performance Einbußen in Grenzen. Hingegen bei einer dokumentbasierten Datenbank ist dieser Effekt vervielfacht. Daher kann die Entscheidung über den verwendeten Aggregationsschnitt durchaus von einer konkreten Technologie beeinflusst werden. 

%TODO: ,da erstezten durch andere Wörte in der ganzen Bachelorarbeit

\subsection{Parallele Bearbeitung eines großen Aggregates}
% TODO: Datenbankanomalien erklären etc.
%TODO: Lockin method
Aufgrund dessen, dass ein Aggregat eine transaktionale Grenze abbildet, wirkt sich der Aggregationsschnitt auf die mögliche Parallelität der Anfragen aus. Ausgehend von \emph{Variante A} resultiert eine Bearbeitung der Daten des Baskets in der Speicherung des kompletten Warenkorbs in der Datenbank. Bei Schreibprozessen können Anomalien auftreten wodurch die Transaktion bzw. der Schreibvorgang abgebrochen werden muss. Eine mögliche Anomalie ist das sogenannte 'Lost Update'-Problem. Es kann auftreten wenn zwei Transaktionen den gleichen Datensatz zeitgleich bearbeiten. Sie beginnen ihre Operationen auf den selben Startzustand und schreien ihre Ergebnisse zurück in die Datenbank. Dabei kann die Änderungen einer Transaktion sofort durch eine andere überschrieben werden und dessen Datenänderungen gehen verloren.

Konkretisiert kann dieses Problem anhand des Baskets. Zwei Personen fügen beispielsweise einen neuen Artikel zu ein und demselben Warenkorb hinzu. Dies kann zum Beispiel bei einer Wishlist auftreten, welche von einer Personengruppe bearbeitet werden kann. Der erste Kunde legt hierbei ein neues Handy in den Warenkorb, wohingegen zeitgleich ein anderer Nutzer einen Fernseher hinzufügt. Beide Transaktionen starten mit einem leeren Warenkorb und schreiben in die Datenbank einen aktualisierten Datensatz mit nur einem Artikel. Daher geht die Änderung eines der zwei Personen verloren. 

Eine Lösung dieses Problems kann durch optimistischen oder pessimistischen Verfahren erzielt werden. Entweder wird im optimistischen Ansatz anhand eines Versionsfeldes überprüft, ob der Datensatz in der Zwischenzeit geändert worden ist und im Falle dessen zurückgewiesen, oder der Datensatz wird durch die pessimistischen Methode gesperrt und die zweite Transaktion muss warten bis die erste den Schreibprozess abschließt. Dementsprechend ist die zeitgleiche Bearbeitung eines Aggregats eingeschränkt. Existieren Anwendungsfälle in denen eine hohe Parallelität notwendig ist, sollten die Aggregates sofern realisierbar voneinander getrennt werden. 

\subsection{Bewertung des großen Aggregationsschnitts}

Abschließend kann anhand der vorhergehenden Überlegungen der Aggregationsschnitt von \emph{Variante A} bewertet werden.

%TODO: Schreibweise von Sourcecode in der ganzen BA überprüfen. Sourcecode oder Source code

\begin{itemize}[noitemsep,nolistsep,topsep=-2pt]
	\item \textbf{Komplexität: } {Die Umsetzung der Businessanforderungen in der Applikation kann übersichtlich erfolgen. Der Sourcecode muss durch keine komplizierteren Vorgänge ergänzt werden. }
	\item \textbf{Performance: } {Jede Anfrage benötigt das Auslesen des ganzen Baskets. Jedoch ist dies in den meisten Anwendungsfällen ohnehin von Nöten. Ein kleinere Aggregationsschnitts kann die Performance sogar verschlechtern. }
	\item \textbf{Parallelität: } {Eine zeitgleiche Bearbeitung des Baskets oder eines Objektes innerhalb ist nicht möglich.}
	\item \textbf{Client-Freundlichkeit: } {In Hinsicht auf die wichtigsten Anwendungsfälle erfährt der Client keine Einschränkungen und alle Businessanforderungen können erfüllt werden.}
\end{itemize}

\section{Trennung der Zahlungsinformationen von dem Basket-Aggregate}

Damit ein neues Aggregat aus der großen Basket-Klasse herausgeschnitten werden kann, wird ein Root Aggregate benötigt. Aus diesem Grund ist der erste Ansatz eine Entity vom Basket abzutrennen. Hierbei ist der PaymentProcess nur schwach an den eigentlichen Basket gebunden und mögliche Anwendungsfälle beziehen sich meist alleinig auf entweder den Warenkorb und seine Items oder den Bezahlprozess. Daher wird in der \emph{Variante C} die Aggregate in Basket und PaymentProcess, wie in Grafik \ref{fig:VarC}, aufgeteilt. 

\begin{figure}[htbp]
	\centering
	\includesvg[inkscapelatex=false, width=0.80\textwidth]{svg/VarC.svg}
	\caption{Aggregationsschnitt der Variante C}
	\label{fig:VarC}
\end{figure}

Da die Aggregates unabhängig voneinander agieren, müssen sie auch getrennt geladen und abgespeichert werden können. Folglich wird ein neues Repository benötigt, welches diese Operationen für das neue Aggregate absolviert. Die Referenz auf den PaymentProcess wird aus dem Basket entfernt und alle Funktionen, welche Aufrufe auf dieses Objekt benötigt haben, müssen entweder in die PaymentProcess-Klasse verlagert oder durch einen Domainservice durchgeführt werden. Es entstehen Auswirkungen auf die bisherige Funktionsweise und den Datenfluss der Applikation, welche in den kommenden Unterkapiteln anhand der Initiierung des Bezahlvorgangs genauer untersucht werden.

Kurze Zusammenfassung des Anwendungsfalles: 
Bevor ein Bezahlprozess gestartet werden darf, muss eine Evaluierung des Warenkorbzustands stattfinden, wie die Überprüfung der hinzugefügten Zahlungsarten, Kundendaten und errechneten Geldbeträge. Nach erfolgreicher Validierung wird der Warenkorbzustand auf 'freeze' abgeändert und der PaymentProcess kann eingeleitet werden.

\subsection{Eventuelle Konsistenz zwischen Aggregates}
%TODO: Message Broker und Listener in gls

Bei der Implementierung von Variante A ist es möglich, dass das Einfrieren des Warenkorbs und die Initiierung innerhalb einer Transaktion erfolgt. Aufgrund der Richtlinie, dass jede Transaktion nur ein Aggregate bearbeiten darf, müssen somit diese Funktionalitäten aufgespalten werden. Das konkrete Problem, welches sich dabei ergibt, ist im Codebeispiel \ref{lst:eventualConsistency} veranschaulicht.

\begin{minipage}{\linewidth} % No pagebreak inside a minipage
	\begin{lstlisting}[caption={Getrennte Transaktionen für die Initiierung des Bezahlvorgangs}, label={lst:eventualConsistency}, language=Kotlin]
function initializePayment(Basket basket, PaymentProcess paymentProcess) {
	basket.validate()
	basket.freeze()
	basketRepository.store(basket)
	// Mögliches Interleaving anderer Operation, welche zur Abänderung des
	// Baskets und des Validierungsergebnisses führt.
	paymentProcess.initialize()
	paymentProcessRepository.store(paymentProcess)
}
	\end{lstlisting}
\end{minipage}

%TODO: Thread
Zwischen dem Persistieren des eingefrorenen Warenkorb und der Initiierung des PaymentProcesses können aufgrund von Parallelität der Warenkorb durch separate Anfragen weiterhin bearbeitet werden. Konkret könnte eine Bedingung für die Validierung sein, dass die Kundendaten nicht leer sein dürfen. Jedoch wird zwischen Zeile 4 und Zeile 7 in einem parallel laufenden Thread durch einen externen API-Aufruf die Kundendaten entfernt. Dadurch wäre die eigentliche Validierung in Zeile 2 fehlgeschlagen und die Initiierung darf nicht durchgeführt werden, jedoch wird diese dennoch in unseren Beispiel angestoßen, da davon ausgegangen wird, dass sich der Basket in der Zwischenzeit nicht verändert hat. Die diese beiden Operationen nicht als eine atomare Einheit umgesetzt ist, entsteht immer eine Möglichkeit des Interleavings zwischen den einzelnen Codezeilen.

Verdeutlicht wird dieser Effekt bei der Benutzung eines Message Brokers, falls exemplarisch die einzelnen Prozesse in verschiedenen Microservices ablaufen. Hierbei wird die konkrete Initiierung in einem anderen Service durchgeführt, welcher bei Empfang eines bestimmten Events ausgeführt wird. Folglich feuert die Funktion nach Einfrieren des Warenkorbs ein solches Event ab. Ein möglicher Programmablauf ist in Diagramm \ref{fig:VarC-Sequence} zu sehen. 

\begin{figure}[htbp]
	\centering
	\includesvg[inkscapelatex=false, width=0.80\textwidth]{svg/VarC Sequenz.svg}
	\caption{Vereinfachtes Sequenzdiagramm zur Initiierung des Bezahlvorgangs in Variante C}
	\label{fig:VarC-Sequence}
\end{figure}

Der rot markierte Bereich stellt die Zeitspanne dar, in welcher andere Prozesse den Warenkorb weiterhin bearbeiten können und dadurch die eigentliche Initiierung invalide, jedoch weiterhin durchgeführt wird. Als Folge dessen entstehen weitere Herausforderungen für das Domainmodell und die Interleavingsmöglichkeiten müssen stets in Betracht gezogen werden. Diese Art von Konsistenz wird als 'Eventuelle Konsistenz' betitelt, da es einen Zeitpunkt gibt in dem die Businessanforderungen temporär nur \emph{eventuell} erfüllt sind. Generell kann in vielen Anwendungsfällen eine kurzzeitige Abweichung der Voraussetzungen akzeptiert werden, zum Beispiel in einem Gruppenchat hat ein kurzer verzögerter Empfang der Nachrichten unter den Teilnehmern keinen großen Einfluss auf die Nutzererfahrung oder korrekte Funktionsweise der Applikation. Hingegen gilt bei der Initiierung des Zahlungsprozesses ein hoher Fokus auf fiskalisch korrekte Abarbeitung des Prozesses. Clients, welche den aktuellen Stand des Bestellprozess abfragen, erhalten bis zur Speicherung des Payment Aggregates einen veralteten Stand. Dies stellt einen bedeutenden Bruch der Invarianten dar. Folglich kann das Zusammenspiel zwischen Basket und PaymentProcess nicht durch eventuelle Konsistenz gelöst werden ohne ein hohes Risiko einzugehen.

\subsection{Atomare Transaktionen über mehrere Aggregates}

%TODO: Race Conditions in glossary
%TODO: Sehr oft "Aggregate innerhalbt einer Transaktion"
%https://softwareengineering.stackexchange.com/questions/356106/ddd-why-is-it-a-bad-practice-to-update-multiple-aggregate-roots-per-transaction   QUELLE FÜR HOST AUSSAGE
Ein weiterer Ansatz zum Bewältigen des Problems ist der Einsatz einer Transaktion über mehrere Aggregates hinweg, obwohl dies die vorher definierte Richtlinie bricht. Argumentativ muss hierzu zuerst die Frage beantwortet werden, aus welchem Grund überhaupt eine Transaktion nicht mehrere Aggregates bearbeiten darf. Durch Anpassen der Fragestellung wird dieser Aspekt klarer. 

Der Hintergedanke des Einsatzes von Aggregates ist eine Gruppierung von Klassen, welche vor und nach einer Transaktion stets konsistent sein müssen. Dies schützt die Applikation vor invaliden Zuständen und erlaubt die Annahme, dass alle Businessvoraussetzungen erfüllt sind. Kann diese Eigenschaft nicht garantiert werden, muss die Software und ihre Clients eventueller Konsistenz handhaben können. Die Aggregationsgrenzen sind somit mit der transaktionalen Konsistenz äquivalent. Dadurch entspricht die Speicherung zweier Aggregates innerhalb einer einzelnen Transaktion eine Überschreitung dieser Grenzen und lässt vermuten, dass der Aggregationsschnitt neu eingeteilt werden muss. Die Richtlinie stellt folglich lediglich ein Indiz für korrektes bzw. inkorrektes Design der Aggregates dar. Bedenklich ist alleinig, wenn die zugehörigen Aggregates auf unterschiedlichen Datenbankhosts liegen. Eine atomare Transaktion ist dadurch unmöglich, wodurch eine solche Architektur die Probleme einer eventuell konsistenten Applikation entwickelt und Interleavings auftreten können. Bei einer Microservice Architektur tritt dieser Fall oft ein, da jede einzelne Applikation meist eine eigene Datenbank auf unterschiedlichen Hosts besitzen.

%TODO: https://docs.mongodb.com/manual/core/write-operations-atomicity/
Eventuelle Konsistenz ist aus den Gründen des vorgehenden Unterkapitels nicht anwendbar und für die Checkout-Software existiert aktuell kein Anlass zur Annahme, dass zukünftig mehrere Datenbankhosts benötigt werden. Dadurch kann die Überlegung entstehen, das Einfrieren des Warenkorbs und die Initiierung des Bezahlprozesses innerhalb einer Transaktion auszuführen. Dazu ist erforderlich, dass die darunterliegende Datenbank eine Transaktion über mehrere Tabellen beziehungsweise Einträge erlaubt. In diesem Projekt wird eine MongoDB zur Datenspeicherung verwendet, welche seit Version 4 atomare Operationen auf mehrere Dokumente und Collections unterstützt. Collections sind hierbei grundlegend gleichbedeutend mit Tabellen aus relationalen Datenbanken. Unsere Applikation erfüllt dementsprechend diese Voraussetzung und eine Implementierung dieses Lösungsansatzes ist technisch möglich. Die Funktion aus dem Beispiel \ref{fig:VarC-Sequence} wird ergänzt, indem ein optimistisches Sperrverfahren auf die betroffenen Einträge in der Datenbank angewandt wird. Dadurch werden andere Zugriffe auf diesen Basket bzw. PaymentProcess erst ausgeführt, wenn die Initiierung vollständig abgeschlossen ist. Eine Möglichkeit zum Interleaving wird dadurch verhindert. Diese Vorgehensweise kann analog in ähnlichen Szenarien verwendet werden.

Weiterhin besteht die Frage, ob \emph{Variante C} ein valides Aggregationsdesign darstellt, da in vielen Funktionen eine Überschreitung der transaktionalen Grenzen stattfindet. Begründet kann diese Entscheidung dadurch, dass der Bezahlvorgang eine kritische Operation aus rechtlicher Sicht darstellt. Sobald dieser gestartet wird, muss das ganze Datenmodell stets konsistent sein. Wenn es uns nicht erlaubt sein sollte, eine Transaktion über mehrere Aggregates durchzuführen, sind somit alle Aggregationsschnitte, abgesehen von \emph{Variante A}, nicht zulässig. Eventuell kann diese Erkenntnis bereits eine vorläufige Antwort für die initiale Forschungsfrage dieser Arbeit darstellen.

Letztendlich soll die Architektur und das Datenmodell die Businessprozesse optimal unterstützen, während die Software weiterhin flexibel und performant bleibt. Die Richtlinie stellt einzig einen Leitfaden dar, um ein korrektes Design zu erleichtern, jedoch keine absolute Regel. Der Anreiz für eine genauer Unterteilung der Aggregates ist das separate Laden und zeitgleiche Bearbeiten unterschiedlicher Aggregates, welches weiterhin in \emph{Variante C} entlang der Richtlinie möglich ist. Anhand dieser Begründung wird für den Proof-of-Concept angenommen, dass ein solcher Aggregationsschnitt als Designentscheidung vertretbar ist. 

%TODO: Bewertung


\section{Verkleinerung der Aggregates durch Analyse existierender Businessanforderungen}

Die ideale Gruppierung von Klassen zu einem Aggregate hängt stark von den Invarianten ab, welche sie zusammenbinden. Anhand einer Untersuchung von Anwendungsfällen ist es möglich, das Zusammenspiel von Entities und Value Objects innerhalb eines Aggregates klarer herauszukristallisieren und neue Ansätze zur Neuverteilung zu finden.

\subsection{Herausschneiden der Berechnungsergebnisse aus dem Basket-Aggregate}

%TODO: User Story
Zum jetzigen Zeitpunkt existieren einige Performance-Einbußen, welche eventuell durch einen verbesserten Aggregationsschnitt verhindert werden können. Viele Anwendungsfälle erfordern ein Neukalkulation des Baskets, ansonsten wäre sein Zustand inkonsistent, wodurch auch die transaktionalen Grenzen des Aggregates ungültig werden würden. In den meisten User Stories fügt der Kunde erst die gewünschten Artikel zum Warenkorb hinzu und öffnet danach Basket, sobald der Kauf abgeschlossen werden sollte. Dadurch ist es möglich die Neuberechnung der Preise erst bei Abruf explizit durchzuführen und Berechnungszeit einzusparen. Zudem werden weniger Daten zwischen Client und Checkout-Software gesendet, wodurch die Netzwerklast vor allem bei mobilen Touchpoints verringert wird. Dieses Design kommt allerdings mit einigen Fragen, welche zuerst beantwortet werden müssen.

\textbf{Ist die Trennung der Kalkulation vom Warenkorb überhaupt möglich aus Sicht des Business?}

Bevor Überlegungen über die Umsetzung des neuen Aggregationsschnittes stattfinden können, müssen es die Businessanforderungen zulassen. Aus technischen Gründen hätte die Abspaltung positive Auswirkungen, jedoch kann es vorkommen, dass die Clients bei jedem Aufruf der API auch ein CalculationResult erwarten. Ist dies immer oder in den meisten Anforderungen der Fall, kann die Trennung nicht sinngemäß durchgeführt werden, ohne auf die Probleme der bisherigen Aggregationsschnitte zu stoßen. Zum Zwecken der Analyse wird angenommen, dass eine solche Änderung für die Touchpoints akzeptabel ist.

\textbf{Wann muss der Basket sowohl als auch das CalculationResult bearbeitet werden?}


Als Folge der gewonnen Erkenntnisse kann es problematisch sein, zwei Aggregates gleichzeitig anzupassen. Das Ergebnis der Preisberechnung wird nur bei der Anzeige des ganzen Warenkorbs benötigt, daher sind alle Operationen, welche den Gesamtpreis während der Einsicht des Baskets manipulieren bedenklich. Um diese Situationen ausfindig machen zu können, muss der Checkout-Prozess genauer untersucht werden. In der Abbildung \ref{fig:Checkout-Process} sind die zwei relevanten Seiten des Checkouts dargestellt. Die roten Pfeile zeigen auf wichtige Stellen des Warenkorbs für dieses Abschnitt.

\vspace{0.5cm}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{bilder/Checkout.png}
	\caption{Aktueller Checkout-Prozess des Onlineshops von MediaMarkt.de}
	\label{fig:Checkout-Process}
\end{figure}

Eine Neukalkulation findet statt sofern die Anzahl der Produkte im Warenkorb oder die Lieferkosten manipuliert werden. Ersteres kann außerhalb des Warenkorbs geschehen oder durch Hinzufügen von Services während der Anzeige des Baskets. Ebenfalls kann die Fulfillment-Methode und Lieferadresse angepasst werden, wodurch sich die Lieferkosten ändern können. Somit existieren einige Anwendungsfälle in denen eine Transaktion über beide Aggregate hinweg notwendig ist.

\textbf{Gibt es Invarianten zwischen den Warenkorb und den CalculationResult?}

Die Businessanforderung, dass das Berechnungsergebnis stets aktuell sein muss, wurde bereits gelockert. Verbleibend ist es zudem Notwendig aus rechtlichen Gründen, dass sich der Preis nach Initiierung des Bezahlvorgangs nicht ändert. Dieses Problem kann allerdings nicht auftreten, da der Warenkorb selbst nicht mehr manipuliert werden darf, somit bleibt der Gesamtpreis ebenfalls unberührt. Weitere Voraussetzungen existieren zum jetzigen Zeitpunkt nicht, jedoch müssen eventuelle zukünftige Anwendungsfälle berücksichtigt werden, ansonsten kann die Flexibilität der Anwendung gefährdet sein. 

Zur Veranschaulichung kann Auswirkungen einer neuen Regelung untersucht werden. Beispielsweise wird angenommen, dass der Gesamtpreis eines Warenkorbs nicht über 20.000€ liegen darf. In diesem Fall würde eine Anpassungen des Basket auch eine Neukalkulation benötigen, wodurch die Abtrennung des CalculationResults sinnfrei wird. Allerdings kann eine mildere Form dieser Richtlinie keine negativen Effekt besitzen, indem die Prüfung erst bei der Initiierung des Bezahlvorgangs ausgeführt wird, da zu diesem Zeitpunkt beide Aggregates immer synchron sind und keine Änderungen mehr erfahren können. Weitere erdenkbaren zukünftige Businessanforderungen sollten berücksichtigt werden, bevor ein Neudesign der Applikation durchgeführt wird.

Grundsätzlich scheint eine Abspaltung der Berechnungsergebnisse vom Warenkorb durchaus plausibel zu sein. Diese Vorgehensweise der Analyse kann analog auf verschiedene Anwendungsfälle durchgeführt werden, um weitere Teile des Baskets zu finden, welche separat agieren können. 

%TODO: Gleiche Überschrift oder nciht?
\subsection{Herausschneiden der Checkout-Daten aus dem Basket-Aggregate}

In dem Aktivitätsdiagramm \ref{fig:SL-Checkoutdata} wurde das Hinzufügen der Kundendaten, Bezahlungsmethode und Fulfillment beschrieben. Dieser Prozess ist ein Hinweise darauf, dass diese Daten eventuell aus dem Basket-Aggregat genommen werden können. Die Summe der Attribute wird als 'Checkout-Daten' betitelt und beinhalten Kundendaten, Fulfillment, Rechnungs- und Lieferadresse. Nachteilig ist jedoch, dass dadurch die Value Objects zu einer Entity zusammengefasst werden, da die Rolle des Aggregate Root nur durch Entities verfüllt werden darf. Ähnlich zum vorgehenden Unterkapitel ist eine Untersuchung der Implikationen eines solches Aggregationsschnittes notwendig.

Anpassungen an diesen Daten dürfen nur durchgeführt werden, wenn der Basket im Status 'open' ist. Dadurch muss bei jedem API-Aufruf zuvor der Zustand überprüft und der Warenkorb-Datenbankeintrag gesperrt werden. Aufgrund von möglichen Interleavings kann ansonsten die Initiierung des Bezahlvorgang auf invalide Checkout-Data stattfinden. Weiterhin wird durch das Setzten eines neuen Fulfillments die Neuberechnung des Warenkorbs angestoßen und bei Übergabe eines Payments muss der PaymentProcess aktualisiert werden.

Vorteilhaft an dieser Variante ist, dass der Basket leichtgewichtiger wird und geringere Datenmengen transportiert werden müssen. Zusätzlich bleiben die negativen Auswirkungen der getrennten Collections in der Datenbank gering, da die Anpassungen der Checkout-Daten nur selten in den User Stories vorkommt.

\section{Zusammenführung der vorgehenden Domain-Modelle}

Anhand der vorgehenden Analyse kann ein neuer, zusammengefasster Aggregationsschnitt gebildet werden.  Dieser hebt das CalculationResult, die CheckoutData und den PaymentProcess aus dem Basket heraus in ihre eigenen Aggregates, wie in Figur \ref{fig:VarD} dargestellt. Eine Abspaltung der BasketItems erfordert zu viele zusätzliche Datenbankoperationen, wodurch diese weiterhin unter dem Basket aufgehängt sind. Falls in zukünftigen Szenarien die parallele Bearbeitung der Warenkorbinhalte unerlässlich ist, kann weiterhin die Trennung der beiden Klassen voneinander in Betracht gezogen werden.  

\begin{figure}[htbp]
	\centering
	\includesvg[inkscapelatex=false, width=0.70\textwidth]{svg/VarD.svg}
	\caption{Aggregationsschnitt der Variante D}
	\label{fig:VarD}
\end{figure}

\subsection{Aktualisieren von veralteten Datenständen}

Ähnlich zu anderen Aggregationsschnitte benötigen viele Anwendungsfälle das Laden und Bearbeiten mehrerer Aggregates. Beispielsweise erfordert das Hinzufügen eines neuen BasketItems die Neuberechnung des PaymentProcesses und CalculationResults. Gleichermaßen muss dieser Prozess angestoßen werden, wenn das Fulfillment in der CheckoutData bearbeitet und die Versandkosten des Warenkorbs sich dadurch ändern. In einer solchen Situation sollte die Neuberechnung allerdings nicht sofort stattfinden, ansonsten gehen die Performance-Verbesserungen durch eine Kalkulation erst bei Bedarf verloren. Aus diesem Grund wird eine Zusatzinformation benötigt, um zu indizieren, dass der aktuelle Berechnungswert veraltet ist. In der konkreten Implementierung wurde zu diesem Zweck ein 'Outdated'-Wahrheitswert in dem Basket- und CheckoutData-Aggregate hinterlegt. Bei Zustandsänderungen, welche den Gesamtwert des Warenkorbs beeinflussen wird dieser auf 'wahr' gesetzt. Sobald ein CalculationResult des dazugehörigen Baskets aus der Datenbank geladen wird, findet auch eine Neuberechnung statt, sofern der 'Outdated'-Wert wahr ist, welche zugleich auch den PaymentProcess aktualisiert. 

\subsection{Dependency Injection von Services in Domain-Driven Design}

Zur Durchführung der Applikationslogik werden Services und Repositories benötigt. Dies stellt die Frage, an welchen Stellen die Funktionsaufrufe im Code stattfinden und wie die Services an das Objekt weitergegeben wird. In diesem Proof-of-Concept wird für die Initiierung von Objekten das Prinzip der Dependency Injection verwendet. Ein Framework erstellt erforderlichen Objekte durch ihren Konstruktor indem die Parameter ebenfalls injiziert werden. Dadurch entsteht ein rekursives Muster bis alle notwendigen Objekte erzeugt sind.

\textbf{Injektion des Services in ein Aggregate durch das Repository}

Eine Realisierungsmöglichkeit ist die Haltung und Aufrufen einer Referenz im Aggregate selbst. Folglich muss beim Lesen der Datensätze aus der Datenbank alle relevanten Service durch das Repository in das Aggregate injiziert werden. Im kurzen Beispielcode \ref{lst:injection} wird dieser Gedanke verdeutlicht.

\begin{minipage}{\linewidth} % No pagebreak inside a minipage
	\begin{lstlisting}[caption={Injektion des Services in ein Aggregate durch das Repository}, label={lst:injection}, language=Kotlin]
class Aggregate {
	
	variable SomeService domainService
	
	// Setzen des konkreten Service
	function inject(SomeService domainService) {
		this.domainService = domainService
	}
}
class AggregateRepository {
	
	function load(Id id) returns Aggregate {
		variable aggregate = searchInDatabase(id)
		aggregate.inject(someService)
		return aggregate
	}
	
}
	\end{lstlisting}
\end{minipage}

Jedoch hat sich diese Methodik bei der Implementierung als problematisch erwiesen. Einerseits ist es fragwürdig, ob Datenklassen aus Programmiersicht überhaupt Referenzen auf Services halten sollten, da äußere Abhängigkeiten in das innere Datenmodell getragen werden. Davon abgesehen erhöht sich stark die Wahrscheinlichkeit auf eine 'Circular Dependency' (dt. Zirkelbezug) innerhalb der Repositories, weil sie selbst alle Services besitzen müssen, um diese den Aggregate zu injizieren. Das bedeutet konkret, dass die Repositories so miteinander in Abhängigkeit stehen können, sodass ein endloser Zyklus während der Dependency Injection entsteht. Verdeutlicht wird dieser Effekt anhand eines sachbezogenen Anwendungsfalles in Abbildung \ref{fig:CircularDependency}. In dem Beispiel benötigt das 'CheckoutDataRepository' das 'BasketDataRepository' zur Initiierung und anders herum erfordert das 'BasketDataRepository' das 'CheckoutDataRepository'. Dadurch ist es unmöglich ein Objekt der jeweiligen Klasse zu erzeugen und die Applikation ist nicht mehr ausführbar. In der Checkout-Software stehen die Aggregates in enger Bindung zueinander und benötigen zur Validierung somit ihre gegenseitigen Repositories. In Variante A kann ein solcher Zyklus nicht auftreten, da nur ein Repository existiert.

\begin{figure}[htbp]
	\centering
	\includesvg[inkscapelatex=false, width=0.70\textwidth]{svg/Circular Dependency.svg}
	\caption{Beispiel einer Circular Dependency}
	\label{fig:CircularDependency}
\end{figure}

\textbf{Auslagerung der Referenz in einen Domainservice}

Ein anderer Lösungsansatz kann das Extrahieren einer Teilfunktionalität aus dem Aggregat in einen dafür vorgesehenen Domainservice darstellen. Das Codebeispiel \ref{lst:extract} implementiert einen Service zur Validierung einer Invariante. 

\begin{minipage}{\linewidth} % No pagebreak inside a minipage
	\begin{lstlisting}[caption={Auslagerung der Referenz in einen Domainservice}, label={lst:extract}, language=Kotlin]
class DomainService {
	// Überprüfung von aggregate.isActionValid() kann unabsichtlich umgangen werden
	// Durch direkten Aufruf von aggregate.doStuff()
	function doStuff(Aggregate aggregate) {
		if (someService.isActionValid()) {     
			aggregate.doStuff()
		}
	}
}
	\end{lstlisting}
\end{minipage}

Die Wahrscheinlichkeit auf eine Circular Dependency wird hierbei gesenkt, da die Injektionen in verschiedenen Klassen verteilt stattfindet. Nachteilig kann weiterhin aus einem anderen Codeabschnitt 'aggregate.doStuff()' aufgerufen werden ohne Durchführung der Validierung. Die Konsistenz des Aggregatzustandes ist somit gefährdet und anhand einer unvorsichtigen Änderung des Quellcodes können neue Bugs entstehen. Unproblematisch sind Serviceaufrufe, welche lediglich Daten erzeugen und diese den Aggregate weitergeben.

\textbf{Übergabe der Referenz an das Aggregate als Parameter}

Ein Aggregate sollte stets selbst alle wesentlichen Invarianten überprüfen, sodass die Ausführung von invaliden Aktionen unterbunden ist. Um dies zu gewährleisten, muss der Service direkt aus dem Aggregate aufgerufen werden, weswegen dieser eine Referenz auf das gefragte Objekt besitzen muss. Als letzte Realisierungsmöglichkeit in Figur \ref{lst:parameter} kann der Service als Parameter übergeben werden.

\begin{minipage}{\linewidth} % No pagebreak inside a minipage
	\begin{lstlisting}[caption={Übergabe der Referenz an das Aggregate als Parameter}, label={lst:parameter}, language=Kotlin]
class DomainService {
	
	variable SomeService someService
	
	function doStuff(Aggregate aggregate) {
		aggregate.doStuff(someService)
	}
}
class Aggregate {
	// Kann nicht umgegangen werden, da Validierung dierekt in Funktion geschieht
	function doStuff(SomeService someService) {
		if (someService.isActionValid()) {
			...
		}
	}
}
	\end{lstlisting}
\end{minipage}

Dies ermöglicht die Kombination der Vorteile der beiden anderen Varianten, jedoch werden die Funktionssignaturen aufgebläht. Aus Sicht der Skalierbarkeit und Fehleranfälligkeit ist generell dieser Ansatz zu bevorzugen, aus welchem Grund auch die Implementierung des Proof-of-Concepts die Domainservices als Parameter übergibt.

\subsection{Performance-Analyse der Aggregationsschnitte unter Einsatz von Lasttests}

Damit eine genaueren Bewertung der Performance von Variante A und D möglich ist, wird ein Lasttest mithilfe der Open-Source-Software 'JMeter' realisiert. Zuerst wurde hierfür ein gängiger Anwendungsfall definiert, welcher folgende Aktionen umfasst: Erstellen eines Baskets, dreimaliges Hinzufügen von Artikeln, Setzen der Checkout-Daten, zweimaliges Abrufen des Warenkorbs, Hinzufügen eines Payments und das Initiieren inklusive Durchführen des Bezahlvorgangs. Nach dem Vorbefüllen der Datenbank mit 1000 Datensätze wird anschließend diese Aktionsfolge in jeder Variation der Aggregationsschnitte innerhalb von zehn simultanen Threads 'X'-mal abgearbeitet. Dieser Vorgang wird drei mal wiederholt, um ungewöhnliche Resultate auszuschließen. Die Ergebnisse wurden dem Anhang hinzugefügt.

Zur simpleren Referenz auf die getesteten Varianten wird die Verwendung von MongoDB als 'M' und von PostgreSQL auf 'P' abgekürzt. Weiterhin ist der Aggregationsschnitt D in die Untertypen 'F' bzw. 'C' unterteilt. Hierbei findet in der Abwandlung 'C' stets die Neuberechnung des Kalkulationsergebnis statt, wohingegen bei 'F' anhand von Flags erkennt wird, wann eine Neukalkulation notwendig ist. Folglich steht beispielsweise die Variante D-PF für den Aggregationsschnitt D mit einer PostgreSQL-Datenbank und Flags.

\textbf{Annahmen und Bemerkungen}

\comment{In realen Umständen beträgt die Zeitspanne, in welcher die Software lediglich auf eine Antwort der externen Aufrufe wartet, für diesen Anwendungsfall insgesamt durchschnittlich 465 Millisekunden anhand des Checkout-Monitorings. Sofern ein Aggregationsschnitt öfters Informationen von Systemen benötigt als andere, muss eine Simulation dieser Wartezeit zur Wahrung der Integrität eingebaut werden. Da alle Varianten aktuell eine identische Anzahl an API-Abfragen aufweisen, kann diese Tatsache im Performance-Test theoretisch vernachlässigt werden. Aus diesem Grund existieren zwei Durchführungen des Teste, einerseits inklusive der Wartezeiten-Simulation und andererseits ohne diese. Das Ergebnis der letzteren Abwandlung ist in Tabelle \ref{fig:performance-delay} zusammengefasst.}

%TODO: Connection-Pools in gls
Die Performance-Analyse dient lediglich als genereller Vergleich und weicht je nach Anwendungsfall und Software ab. Hinzukommt, dass die Ergebnisse je nach Hardware und Netzwerk unterschiedlich ausfallen. Zudem können weiterhin Optimierungsoptionen vorgenommen werden, wie die angepasste Einstellung des Connection-Pools oder das Einsparen von ganzen Datenbankoperationen durch Caching. Anhand der Analyse sollen vorgehende Aussagen bewiesen und Argumente für das Fazit gebildet werden.

\textbf{Erster Testdurchlauf und hieraus ableitbare Aussagen}

Zu Beginn wurde der Proof-of-Concept für Variante A und D mitsamt ihren Abwandlungen implementiert und sachbezogene KPIs anhand des obigen Testaufbaus ausgewertet. Das Ergebnis ist in Tabellenform im Anhang unter \ref{fig:performance-mongo} zu finden. Um die Auswirkungen der Verwendung einer relational Datenbank zu beobachten, wurde ebenfalls der Versuch mit einer PostgreSQL-Datenbank wiederholt. Die Auswertungen sind in Tabelle \ref{fig:performance-postgres} hinterlegt. Um einen schnellen Überblick zu bieten, wurde die durchschnittlichen 'Abläufe pro Sekunde' über einen Gesamtumfang von 10.000 Abläufen per Variante in der Grafik \ref{fig:PerformanceDefault} abgebildet.

\begin{figure}
	\centering
	\footnotesize
	\includesvg[width=0.70\textwidth]{svg/Performance Default.svg}
	\caption{Performance-Ergebnisse aus dem ersten Testdurchlauf}
	\label{fig:PerformanceDefault}
\end{figure}

Mithilfe der Verwendung von Flags werden Neukalkulationen eingespart im Austausch für zusätzliche Datenbankoperationen, jedoch sind die eigentlichen Berechnungen des Warenkorbs in dem verkleinerten Proof-of-Concept trivial, weshalb zu beobachten ist, dass ein solches Vorgehen insgesamt zu einer geringeren Performance führt. In der aktuellen Live-Applikation kann aufgrund der Komplexeren Berechnungsgrundlage dies weitaus performanter ausfallen. Negativ ist anzumerken, dass die Verwendung von Flags einhergeht mit einem komplexeren Programmablauf, da die Aktualisierung von Daten asynchron stattfinden. Schlussendlich kann eine genaue Aussage ohne den Ausbau der getesteten Software über den Vergleich zwischen D-C und D-F nicht getroffen werden.

In einem früheren Kapitel wurde die These aufgestellt, dass die Unterteilung von großen Aggregaten in kleinere unter Verwendung einer dokument-orientierten Datenbank in geringeren oder sogar negativen Performance-Gewinnen resultieren kann als bei Einsatz einer relationale Datenbank als darunterliegenden Datenspeicher. Diese Aussage rührt auf der Basis, dass mehr Datenbankoperationen bei einer MongoDB benötigt werden sobald die Anzahl der Aggregates steigen, da zuvor alle Daten in einer einzelnen Collection abgespeichert werden konnten. Hingegen ist in relationalen Datenbanksystemen aufgrund von Mehrfachbeziehungen und zur Einhaltung von Normalformen ein Aggregat bereits in mehrere Tabellen verteilt und die weitere Abspaltung von Objekten führt zu insgesamt weniger neuen Relationen bzw. Tabellen. In Tabelle \ref{fig:durationofexecution} wurde der Median über die Ausführungsdauer eines Anwendungsfalles pro Aggregationsschnitt gebildet und die Gesamtzahl der hierfür benötigten Datenbankoperationen aufgelistet. 

\begin{table}
	\centering
	\begin{tabular}{ | >{\raggedright\arraybackslash}m{0.20\textwidth} || c | c | c | c | c | c | } 
		\hline
		Variante & A-M & D-MC & D-MF & A-P & D-PC & D-MF \\ 
		\hline
		Median-Dauer & 35ms & 31ms & 35ms & 56ms & 49ms & 56ms \\
		\hline
		Leseoperationen & 15 & 43 &  55 &  84 & 137 & 170 \\
		\hline
		Schreiboperationen & 15 & 27 & 28 & 108 & 98 & 127 \\
		\hline
	\end{tabular}
	\caption{Median der Ausführungszeit und Datenbankoperationen eines Durchlaufes}
	\label{fig:durationofexecution}
\end{table}

Der Performance-Unterschied beläuft sich auf 4 Millisekunden zwischen A-M und D-MC, sofern eine MongoDB als Datenbankmanagementsystem genutzt wird, wohingegen ein Einsparung von 6 Millisekunden bei einer PostgreSQL möglich ist. Dieser Effekt kann weiterhin deutlicher in kommende Testaufbaus beobachtet werden. Eine Frage, welche sich aus den Daten ergibt, ist, warum der Umbau zu Variante D überhaupt einen Performance-Gewinn mit sich bringt, obwohl dies mit mehr Datenbankoperationen einhergeht. 

Zum Speichern oder Laden von Datensätzen muss eine sogenannte De- bzw. Serialisierung stattfinden, damit die Daten richtig interpretiert werden können. Bei genauer Untersuchung der Datenbankzugriffe stellt sich heraus, dass dieser Vorgang den Großteil der Bearbeitungszeit in Anspruch nimmt, nicht wie zu vermuten die eigentliche Datenbankoperation. Deshalb sind die Variationen A insgesamt langsamer, da mehr Daten verarbeitet werden und somit zugleich die De-/Serialisierungsdauer erhöht wird. Diese Situation entsteht, da die Datenbank auf der gleichen Maschine ausgeführt wird wie die eigentliche Software. Die Kommunikation zwischen den Systemen ist nicht vom Netzwerk abhängig und ein Datenbankzugriff beläuft sich auf circa 1,5 Millisekunden. In den meisten Produktivumgebungen ist die Datenbank allerdings physisch getrennt, woraus Verzögerungen durch den Datentransport über das Netzwerk entstehen. Zur Simulation dieses Phänomens wird ein weiterer Performance-Test durchgeführt. 

\textbf{Aushängen der Datenbank in eine Cloud-Umgebung}

Damit eine ähnlichere Situation zu Produktivanwendungen geboten werden kann, wurde bei Cloud-Anbietern jeweils eine MongoDB und PostgreSQL in einem frankfurter Datenzentrum mit 8 Gigabyte Arbeitsspeicher und 4 virtuellen Kernen angemietet. Der vorherige Testaufbau wird mit diesen Datenspeichern wiederholt und tabellarisch dem Anhand unter \ref{fig:performance-database} hinzugefügt. Das Diagramm \ref{fig:PerformanceDatabase} bietet die dazugehörige grafische Auswertung.

\begin{figure}
	\centering
	\footnotesize
	\includesvg[width=0.70\textwidth]{svg/Performance Database.svg}
	\caption{Performance-Ergebnisse bei Auslagerung der Datenbanksysteme}
	\label{fig:PerformanceDatabase}
\end{figure}

Die zusätzlichen Datenbankoperationen wirken sich stark nun auf die Performance des Proof-of-Concepts aus. Der mögliche Durchsatz von Variante A ist höher als der verkleinerte Aggregationsschnitt, da die De-/Serialisierung nur noch ein Bruchstück der Gesamtdauer ausmacht und die eigentliche Datenbankverbindung hingegen mehr Zeit in Anspruch nimmt. Konkret kann die aktuelle Bearbeitungszeit der Tabelle \ref{fig:durationofexecutionDatabase} entnommen werden. Die Differenz zwischen Variante A-M und D-MC beträgt hierbei durch das Netzwerk 751 Millisekunden. Es muss beachtet werden, dass die Kommunikation mit den Datenspeicher die einzige Wartezeit der Applikation darstellt, wodurch der Einfluss auf die Performance unnatürlich hoch ausfällt und die Testergebnisse weiterhin alleinig als Veranschaulichung dienen. Zudem kann die Performance erhöht werden, sofern die Systeme physisch näher zusammenliegen oder innerhalb eines Cloud-Anbieters ein virtuelles Netzwerk über die Softwarekomponenten erstellt wird. 

\begin{table}
	\centering
	\begin{tabular}{ | >{\raggedright\arraybackslash}m{0.20\textwidth} || c | c | c | c | c | c | } 
		\hline
		Variante & A-M & D-MC & D-MF & A-P & D-PC & D-MF \\ 
		\hline
		Median-Dauer & 615ms & 1366ms & 1622ms & 3799ms & 4543ms & 5750ms \\
		\hline
	\end{tabular}
	\caption{Median der Ausführungszeit und Datenbankoperationen eines Durchlaufes}
	\label{fig:durationofexecutionDatabase}
\end{table}
 

\textbf{Simulation von Wartezeiten bei Aufrufen von externen APIs}

Die Tatsache, dass Aufrufe an externe Systeme in zusätzlicher Wartezeit resultiert, wurde bis jetzt in den Performance-Test vernachlässigt. Aus der Analyse von Monitoring-Systemen der aktuellen Produktivanwendung konnten durchschnittliche API-Abrufzeiten gebildet und in die Applikation mit eingebaut werden. Im Mittel verbringt die Software 465 Millisekunden auf Antworten von abhängigen Systemen zu warten, wobei alle Aggregationsschnitte die gleiche Anzahl an API-Aufrufe erfordern. Sollte dies nicht der Fall sein, muss ein solcher Fakt ebenfalls mit in die Bewertung der Aggregates mit einfließen. Der Testablauf wird auf Basis des ersten Tests dementsprechend erneut durchgeführt inklusive der Simulation der Wartezeiten. Die gemessenen Werte befinden sich in Tabelle \ref{fig:performance-delay} und im Balkendiagramm \ref{fig:PerformanceDelay}.

\begin{figure}
	\centering
	\footnotesize
	\includesvg[width=0.70\textwidth]{svg/Performance Delay.svg}
	\caption{Performance-Ergebnisse unter Beachtung der Wartezeiten bei API-Aufrufe}
	\label{fig:PerformanceDelay}
\end{figure}

\textbf{Fazit aus dem Performance-Test}

Jegliche Art von Kommunikation mit externen Systemen gehen einher mit erheblichen Performance-Verluste des Proof-of-Concepts, da die eigentliche Datenverarbeitung der Anwendung minimal gehalten wurde. In produktiven Umgebungen sind die Performance-Einflüsse durch das Datenmodell weitaus geringer als in diesem Beispiel, dennoch bleibt die Tendenz gleich, dass ein kleinerer Aggregationsschnitt im Kontext einer Checkout-Software in Kombination mit einer dokumentenorientierten Datenbank negative Auswirkungen besitzt. Folglich fällt die Argumentation der erhöhten Performance weg und die Motivationsgrundlage für einen Umbau wird geschwächt. 


\subsection{Bewertung des verkleinerten Aggregationsschnitt}

Die finale Evaluation ist ein Resultat der vorgehenden theoretischen Überlegungen, ein Vergleich mit anderen Varianten des Aggregationsschnitts und ihren tatsächlichen Implementierungen.

Innerhalb eines solchen Domain-Modells ist es möglich, die Kalkulation des Warenkorbs erst bei expliziter Abfrage der Ergebnisse erfolgen, wodurch insgesamt unnötige Berechnungszeit eingespart werden kann. Ein solches Vorgehen erlaubt es bei einer hohen Auslastung der Systeme multiplikativ an Performance zu gewinnen. Zusätzlich müssen weniger Nutzlast zwischen den Clients und den Server gesendet werden, da die einzelnen Aggregates eine geringere Anzahl an Attributen beinhalten. Es muss allerdings genauer Untersucht werden, ob die zusätzlichen Datenbankabfragen diesen Effekt negieren oder dennoch insgesamt ein positiver Einfluss auf die Applikationsgeschwindigkeit zu verzeichnen ist. 

\begin{itemize}[topsep=-2pt]
	\item \textbf{Komplexität: } {Viele Prozesse benötigen zum Abfragen von externen Informationen oder für die Einhaltung von Invarianten mehr als ein Aggregat, wodurch zusätzlichen Funktionsaufrufe und Übergabeparameter eingeführt werden müssen. Dabei leidet die Übersichtlichkeit des Quellcodes. Dennoch ist es beispielsweise möglich durch Verwendung eines Kontextobjekts, auf welches überall in der Applikation Zugriff besteht, diese Auswirkungen einzudämmen, indem geladene Aggregate dort eingespeichert und abgerufen werden.
		
	Das Transaktionsmanagement gewinnt ebenfalls an Relevanz, sodass Datensätze so kurz wie möglich gesperrt sind. Sofern keine synchronen Aufrufe stattfinden, wirkt sich dies jedoch nicht bemerkbar auf die Performance aus. 
	
	Weiterhin muss für die Neuberechnung der Preise zum Abarbeiten von Nebeneffekten Flags eingeführt werden, sofern eine Vermeidung von extra Schreibprozesse angestrebt wird. 
	
	\emph{Insgesamt gewinnt die Applikation generell an Komplexität, welche je nach Realisierungsmethode stärker oder schwächer ausfallen kann.}}

	\item \textbf{Performance: } { \emph{Basierend auf die vorgehende Analyse ist ein Verlust von Performance vorhanden, da in der Live-Umgebung eine MongoDB verwendet wird. Dies stellte den eigentlichen Hauptgrund für einen Umgestaltung der Applikation dar.} }
	
	\item \textbf{Parallelität: } { Generell können zwei unterschiedliche Aggregates unabhängig voneinander bearbeitet werden. Als konkretes Beispiel ist die Bearbeitung von enthaltenen Artikeln und das setzen von Checkout-Informationen gleichzeitig möglich. Eine tatsächliche Anwendung dieses Falles ist allerdings kaum denkbar. Sofern zusätzlich die Abspaltung der BasketItems hinzukommt, gewinnt dieser Aspekt an Bedeutung. Aus zuvor dargebotenen Gründen ist die erhöhte Transaktionsanzahl nicht vertretbar, da in den meisten Fällen der Warenkorb einer einzelnen Person gehört. \emph{Die gewonnene Parallelität ist folglich nahezu vernachlässigbar bzw. nicht anwendbar.}}
	%TODO: Api-Contract erklärt irgendwo?
	\item \textbf{Client-Freundlichkeit: } { Touchpoints erhalten als Antwort auf API-Anfragen in dieser Variante nur einen Teilaspekt des Baskets, denn andererseits müssten wieder alle Aggregate geladen werden, wodurch der Sinn einer Trennung verloren geht. Vornherein findet mit den Clients eine Klärung über die erwarteten Antwortdaten mithilfe einer API-Vereinbarung statt, sodass diese ohne zusätzliche Anfragen weiterhin ihre Arbeitsprozesse abwickeln können. Die Verwendung von Technologien wie GraphQL kann diese Anforderung erleichtern. \emph{Letztendlich sind Clients nur maximal neutral von der neuen Architektur betroffen.}}
\end{itemize}

Zusammenfassend existiert nur sehr beschränkt ein wirklicher Grund für die Anwendung von Variante D oder ähnlichen Aggregationsschnitten.

%TODO: Add Bewertung zu allen Aggregationsschnitte